{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a Executive summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The main focus of this project  is to predict whether  clients will open  term deposits (variable y) using sociodemographic, social and economic context attributes and account attributes.\n",
    "\n",
    " Different supervised classification models were used .\n",
    "\n",
    "The results show that the Logistic regression model (using Ridge algorithm) is the best predictor based on ROC score and the most important features explored by Ride were. \n",
    "    Consumer price index, Communication type cellular \n",
    "    Contact Month Jul, Consumers confidence Index\n",
    "    Age, Job technician"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data fields\n",
    "Input variables:\n",
    "\n",
    "### 1.2a Bank client data:\n",
    "\n",
    "1 - age (numeric)\n",
    "\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "### 1.2b Related with the last contact of the current campaign:\n",
    "\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "\n",
    "### 1.2c Other attributes:\n",
    "\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "\n",
    "\n",
    "### 1.2d social and economic context attributes\n",
    "\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target): \n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data= pd.read_csv('data_visualisation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Unnamed: 0', 'age', 'job', 'marital', 'education',\n",
       "        'have_credit_by_default', 'housing_loan', 'personal_loan',\n",
       "        'communication_type', 'month', 'last_contact_day',\n",
       "        'last_contact_duration', 'no_contact_with_client',\n",
       "        'n_days_clcontact_prev_campaign',\n",
       "        'no_contct_bef_campaign_wth_samepersn', 'employee_variatn_rate',\n",
       "        'consmr_price_indx', 'conmrs_confidnc_indx', 'y'],\n",
       "       dtype='object'), (2999, 19))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns, raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data.head()\n",
    "raw_data = raw_data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>have_credit_by_default</th>\n",
       "      <th>housing_loan</th>\n",
       "      <th>personal_loan</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>month</th>\n",
       "      <th>last_contact_day</th>\n",
       "      <th>last_contact_duration</th>\n",
       "      <th>no_contact_with_client</th>\n",
       "      <th>n_days_clcontact_prev_campaign</th>\n",
       "      <th>no_contct_bef_campaign_wth_samepersn</th>\n",
       "      <th>employee_variatn_rate</th>\n",
       "      <th>consmr_price_indx</th>\n",
       "      <th>conmrs_confidnc_indx</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>346</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>wed</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>sep</td>\n",
       "      <td>thu</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.199</td>\n",
       "      <td>-37.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>admin</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>sep</td>\n",
       "      <td>mon</td>\n",
       "      <td>290</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.199</td>\n",
       "      <td>-37.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>services</td>\n",
       "      <td>divorced</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>basic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>single</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>admin</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>553</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>wed</td>\n",
       "      <td>698</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44</td>\n",
       "      <td>admin</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>wed</td>\n",
       "      <td>191</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46</td>\n",
       "      <td>admin</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>45</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>849</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>326</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>39</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>mar</td>\n",
       "      <td>mon</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.369</td>\n",
       "      <td>-34.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>626</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>388</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>479</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>47</td>\n",
       "      <td>admin</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>34</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>48</td>\n",
       "      <td>services</td>\n",
       "      <td>divorced</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>50</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>40</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>tue</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>31</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>39</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>488</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>38</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>58</td>\n",
       "      <td>admin</td>\n",
       "      <td>divorced</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>oct</td>\n",
       "      <td>thu</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.798</td>\n",
       "      <td>-40.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>37</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>fri</td>\n",
       "      <td>674</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>34</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>35</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>39</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>thu</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>78</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>oct</td>\n",
       "      <td>thu</td>\n",
       "      <td>321</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>92.431</td>\n",
       "      <td>-26.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>43</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.876</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>49</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>thu</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>32</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>293</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>58</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>42</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>32</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>1119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>wed</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>45</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>43</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>288</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>53</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>42</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>40</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>179</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>41</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>basic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>53</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>tue</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>60</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>oct</td>\n",
       "      <td>mon</td>\n",
       "      <td>338</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.601</td>\n",
       "      <td>-49.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>32</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>thu</td>\n",
       "      <td>485</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>67</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2999 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age            job   marital            education  \\\n",
       "0      30    blue-collar   married                basic   \n",
       "1      39       services    single          high.school   \n",
       "2      25       services   married          high.school   \n",
       "3      38       services   married                basic   \n",
       "4      47          admin   married    university.degree   \n",
       "5      32       services    single    university.degree   \n",
       "6      32          admin    single    university.degree   \n",
       "7      41   entrepreneur   married    university.degree   \n",
       "8      31       services  divorced  professional.course   \n",
       "9      35    blue-collar   married                basic   \n",
       "10     25       services    single                basic   \n",
       "11     36  self-employed    single                basic   \n",
       "12     36          admin   married          high.school   \n",
       "13     47    blue-collar   married                basic   \n",
       "14     29          admin    single          high.school   \n",
       "15     27       services    single    university.degree   \n",
       "16     44          admin  divorced    university.degree   \n",
       "17     46          admin  divorced    university.degree   \n",
       "18     45   entrepreneur   married    university.degree   \n",
       "19     50    blue-collar   married                basic   \n",
       "20     55       services   married                basic   \n",
       "21     39     technician  divorced          high.school   \n",
       "22     29     technician    single    university.degree   \n",
       "23     40     management   married          high.school   \n",
       "24     44     technician   married  professional.course   \n",
       "25     38     technician   married  professional.course   \n",
       "26     36     technician  divorced  professional.course   \n",
       "27     28    blue-collar   married                basic   \n",
       "28     47          admin    single  professional.course   \n",
       "29     34          admin   married    university.degree   \n",
       "...   ...            ...       ...                  ...   \n",
       "2969   48       services  divorced          high.school   \n",
       "2970   50     management   married    university.degree   \n",
       "2971   40    blue-collar   married                basic   \n",
       "2972   31          admin   married    university.degree   \n",
       "2973   39    blue-collar   married                basic   \n",
       "2974   38          admin   married          high.school   \n",
       "2975   58          admin  divorced          high.school   \n",
       "2976   37     technician   married  professional.course   \n",
       "2977   34       services   married          high.school   \n",
       "2978   35     technician   married          high.school   \n",
       "2979   39   entrepreneur   married    university.degree   \n",
       "2980   78        retired   married                basic   \n",
       "2981   43    blue-collar    single          high.school   \n",
       "2982   49     technician  divorced    university.degree   \n",
       "2983   32     technician   married  professional.course   \n",
       "2984   58   entrepreneur   married    university.degree   \n",
       "2985   42          admin   married    university.degree   \n",
       "2986   32    blue-collar   married  professional.course   \n",
       "2987   31     technician   married  professional.course   \n",
       "2988   45       services   married  professional.course   \n",
       "2989   43    blue-collar   married                basic   \n",
       "2990   53    blue-collar   married                basic   \n",
       "2991   42          admin   married          high.school   \n",
       "2992   40     technician   married  professional.course   \n",
       "2993   41     management   married    university.degree   \n",
       "2994   47    blue-collar    single                basic   \n",
       "2995   53          admin   married    university.degree   \n",
       "2996   60        retired   married    university.degree   \n",
       "2997   32     technician    single    university.degree   \n",
       "2998   67        retired   married                basic   \n",
       "\n",
       "     have_credit_by_default housing_loan personal_loan communication_type  \\\n",
       "0                        no          yes            no           cellular   \n",
       "1                        no           no            no          telephone   \n",
       "2                        no          yes            no          telephone   \n",
       "3                        no           no           yes          telephone   \n",
       "4                        no          yes            no           cellular   \n",
       "5                        no           no            no           cellular   \n",
       "6                        no          yes            no           cellular   \n",
       "7                   unknown          yes            no           cellular   \n",
       "8                        no           no            no           cellular   \n",
       "9                   unknown           no            no          telephone   \n",
       "10                  unknown          yes            no           cellular   \n",
       "11                       no           no            no           cellular   \n",
       "12                       no           no            no          telephone   \n",
       "13                       no          yes            no          telephone   \n",
       "14                       no           no            no           cellular   \n",
       "15                       no           no            no           cellular   \n",
       "16                       no           no            no           cellular   \n",
       "17                       no          yes            no          telephone   \n",
       "18                  unknown          yes           yes           cellular   \n",
       "19                       no           no           yes           cellular   \n",
       "20                  unknown          yes            no           cellular   \n",
       "21                       no           no            no           cellular   \n",
       "22                       no          yes           yes           cellular   \n",
       "23                       no           no           yes           cellular   \n",
       "24                  unknown          yes            no          telephone   \n",
       "25                       no          yes            no           cellular   \n",
       "26                       no           no            no          telephone   \n",
       "27                  unknown           no            no           cellular   \n",
       "28                  unknown           no            no          telephone   \n",
       "29                       no           no            no           cellular   \n",
       "...                     ...          ...           ...                ...   \n",
       "2969                unknown          yes           yes          telephone   \n",
       "2970                     no          yes            no          telephone   \n",
       "2971                unknown          yes            no          telephone   \n",
       "2972                     no           no           yes           cellular   \n",
       "2973                     no           no            no          telephone   \n",
       "2974                     no          yes            no           cellular   \n",
       "2975                     no           no            no          telephone   \n",
       "2976                     no           no           yes           cellular   \n",
       "2977                     no           no            no          telephone   \n",
       "2978                unknown          yes            no           cellular   \n",
       "2979                     no          yes            no           cellular   \n",
       "2980                     no          yes            no          telephone   \n",
       "2981                     no           no           yes          telephone   \n",
       "2982                     no          yes            no          telephone   \n",
       "2983                     no           no            no          telephone   \n",
       "2984                unknown           no            no          telephone   \n",
       "2985                     no          yes            no           cellular   \n",
       "2986                     no           no            no          telephone   \n",
       "2987                     no          yes            no           cellular   \n",
       "2988                     no          yes            no           cellular   \n",
       "2989                unknown          yes            no           cellular   \n",
       "2990                     no           no            no           cellular   \n",
       "2991                     no          yes           yes          telephone   \n",
       "2992                     no           no            no          telephone   \n",
       "2993                unknown          yes            no           cellular   \n",
       "2994                unknown           no            no           cellular   \n",
       "2995                     no           no           yes          telephone   \n",
       "2996                     no          yes            no           cellular   \n",
       "2997                     no           no            no           cellular   \n",
       "2998                     no           no            no           cellular   \n",
       "\n",
       "     month last_contact_day  last_contact_duration  no_contact_with_client  \\\n",
       "0      may              fri                    487                       2   \n",
       "1      may              fri                    346                       4   \n",
       "2      jun              wed                    227                       1   \n",
       "3      jun              fri                     17                       3   \n",
       "4      nov              mon                     58                       1   \n",
       "5      sep              thu                    128                       3   \n",
       "6      sep              mon                    290                       4   \n",
       "7      nov              mon                     44                       2   \n",
       "8      nov              tue                     68                       1   \n",
       "9      may              thu                    170                       1   \n",
       "10     jul              thu                    301                       1   \n",
       "11     jul              thu                    148                       1   \n",
       "12     may              wed                     97                       2   \n",
       "13     jun              thu                    211                       2   \n",
       "14     may              fri                    553                       2   \n",
       "15     jul              wed                    698                       2   \n",
       "16     jul              wed                    191                       6   \n",
       "17     jul              mon                     59                       4   \n",
       "18     aug              mon                     38                       2   \n",
       "19     jul              tue                    849                       1   \n",
       "20     jul              tue                    326                       6   \n",
       "21     mar              mon                    222                       1   \n",
       "22     aug              wed                    626                       3   \n",
       "23     aug              wed                    119                       1   \n",
       "24     may              fri                    388                       7   \n",
       "25     aug              mon                    479                       1   \n",
       "26     may              wed                    446                       1   \n",
       "27     may              mon                     68                       2   \n",
       "28     may              thu                    127                       1   \n",
       "29     aug              tue                    109                       1   \n",
       "...    ...              ...                    ...                     ...   \n",
       "2969   may              mon                    158                       2   \n",
       "2970   may              wed                    117                       2   \n",
       "2971   may              tue                    211                       1   \n",
       "2972   jul              mon                     15                      11   \n",
       "2973   may              wed                    488                      12   \n",
       "2974   nov              tue                     67                       2   \n",
       "2975   oct              thu                     81                       1   \n",
       "2976   jul              fri                    674                       3   \n",
       "2977   jun              tue                     51                       2   \n",
       "2978   jul              tue                    740                       1   \n",
       "2979   nov              thu                    260                       1   \n",
       "2980   oct              thu                    321                       1   \n",
       "2981   may              thu                    137                       1   \n",
       "2982   nov              thu                     30                       1   \n",
       "2983   may              wed                    293                       2   \n",
       "2984   jun              fri                    218                       1   \n",
       "2985   aug              wed                    127                       1   \n",
       "2986   may              thu                   1119                       1   \n",
       "2987   jul              wed                    225                       2   \n",
       "2988   jul              mon                     19                      23   \n",
       "2989   may              fri                    288                       3   \n",
       "2990   aug              tue                     76                       1   \n",
       "2991   jul              mon                    388                       1   \n",
       "2992   jun              fri                    179                       2   \n",
       "2993   aug              thu                    172                       1   \n",
       "2994   may              wed                    159                       1   \n",
       "2995   may              tue                     37                      13   \n",
       "2996   oct              mon                    338                       2   \n",
       "2997   nov              thu                    485                       1   \n",
       "2998   aug              mon                    300                       3   \n",
       "\n",
       "      n_days_clcontact_prev_campaign  no_contct_bef_campaign_wth_samepersn  \\\n",
       "0                                  0                                     0   \n",
       "1                                  0                                     0   \n",
       "2                                  0                                     0   \n",
       "3                                  0                                     0   \n",
       "4                                  0                                     0   \n",
       "5                                  0                                     2   \n",
       "6                                  0                                     0   \n",
       "7                                  0                                     0   \n",
       "8                                  0                                     1   \n",
       "9                                  0                                     0   \n",
       "10                                 0                                     0   \n",
       "11                                 0                                     0   \n",
       "12                                 0                                     0   \n",
       "13                                 0                                     0   \n",
       "14                                 0                                     0   \n",
       "15                                 0                                     0   \n",
       "16                                 0                                     0   \n",
       "17                                 0                                     0   \n",
       "18                                 0                                     0   \n",
       "19                                 0                                     0   \n",
       "20                                 0                                     0   \n",
       "21                                12                                     2   \n",
       "22                                 0                                     0   \n",
       "23                                 0                                     0   \n",
       "24                                 0                                     0   \n",
       "25                                 0                                     0   \n",
       "26                                 0                                     0   \n",
       "27                                 0                                     1   \n",
       "28                                 0                                     0   \n",
       "29                                 0                                     0   \n",
       "...                              ...                                   ...   \n",
       "2969                               0                                     0   \n",
       "2970                               0                                     0   \n",
       "2971                               0                                     0   \n",
       "2972                               0                                     0   \n",
       "2973                               0                                     0   \n",
       "2974                               0                                     0   \n",
       "2975                               0                                     0   \n",
       "2976                               0                                     0   \n",
       "2977                               0                                     0   \n",
       "2978                               0                                     0   \n",
       "2979                               0                                     0   \n",
       "2980                               0                                     0   \n",
       "2981                               0                                     0   \n",
       "2982                               0                                     0   \n",
       "2983                               0                                     0   \n",
       "2984                               0                                     0   \n",
       "2985                               0                                     0   \n",
       "2986                               0                                     0   \n",
       "2987                               0                                     0   \n",
       "2988                               0                                     0   \n",
       "2989                               0                                     1   \n",
       "2990                               0                                     0   \n",
       "2991                               0                                     0   \n",
       "2992                               0                                     0   \n",
       "2993                               0                                     0   \n",
       "2994                               0                                     0   \n",
       "2995                               0                                     0   \n",
       "2996                               0                                     0   \n",
       "2997                               0                                     1   \n",
       "2998                               0                                     0   \n",
       "\n",
       "      employee_variatn_rate  consmr_price_indx  conmrs_confidnc_indx  y  \n",
       "0                      -1.8             92.893                 -46.2  0  \n",
       "1                       1.1             93.994                 -36.4  0  \n",
       "2                       1.4             94.465                 -41.8  0  \n",
       "3                       1.4             94.465                 -41.8  0  \n",
       "4                      -0.1             93.200                 -42.0  0  \n",
       "5                      -1.1             94.199                 -37.5  0  \n",
       "6                      -1.1             94.199                 -37.5  0  \n",
       "7                      -0.1             93.200                 -42.0  0  \n",
       "8                      -0.1             93.200                 -42.0  0  \n",
       "9                       1.1             93.994                 -36.4  0  \n",
       "10                      1.4             93.918                 -42.7  0  \n",
       "11                      1.4             93.918                 -42.7  0  \n",
       "12                      1.1             93.994                 -36.4  0  \n",
       "13                      1.4             94.465                 -41.8  0  \n",
       "14                     -1.8             92.893                 -46.2  0  \n",
       "15                      1.4             93.918                 -42.7  0  \n",
       "16                      1.4             93.918                 -42.7  0  \n",
       "17                      1.4             93.918                 -42.7  0  \n",
       "18                      1.4             93.444                 -36.1  0  \n",
       "19                      1.4             93.918                 -42.7  1  \n",
       "20                      1.4             93.918                 -42.7  0  \n",
       "21                     -1.8             93.369                 -34.8  1  \n",
       "22                      1.4             93.444                 -36.1  0  \n",
       "23                      1.4             93.444                 -36.1  0  \n",
       "24                      1.1             93.994                 -36.4  0  \n",
       "25                      1.4             93.444                 -36.1  1  \n",
       "26                      1.1             93.994                 -36.4  0  \n",
       "27                     -1.8             92.893                 -46.2  0  \n",
       "28                      1.1             93.994                 -36.4  0  \n",
       "29                      1.4             93.444                 -36.1  0  \n",
       "...                     ...                ...                   ... ..  \n",
       "2969                    1.1             93.994                 -36.4  0  \n",
       "2970                    1.1             93.994                 -36.4  0  \n",
       "2971                    1.1             93.994                 -36.4  0  \n",
       "2972                    1.4             93.918                 -42.7  0  \n",
       "2973                    1.1             93.994                 -36.4  0  \n",
       "2974                   -0.1             93.200                 -42.0  0  \n",
       "2975                   -0.1             93.798                 -40.4  0  \n",
       "2976                    1.4             93.918                 -42.7  1  \n",
       "2977                    1.4             94.465                 -41.8  0  \n",
       "2978                    1.4             93.918                 -42.7  1  \n",
       "2979                   -0.1             93.200                 -42.0  0  \n",
       "2980                   -3.4             92.431                 -26.9  0  \n",
       "2981                   -1.8             93.876                 -40.0  0  \n",
       "2982                   -0.1             93.200                 -42.0  0  \n",
       "2983                    1.1             93.994                 -36.4  0  \n",
       "2984                    1.4             94.465                 -41.8  0  \n",
       "2985                    1.4             93.444                 -36.1  0  \n",
       "2986                    1.1             93.994                 -36.4  1  \n",
       "2987                    1.4             93.918                 -42.7  0  \n",
       "2988                    1.4             93.918                 -42.7  0  \n",
       "2989                   -1.8             92.893                 -46.2  0  \n",
       "2990                    1.4             93.444                 -36.1  0  \n",
       "2991                    1.4             93.918                 -42.7  0  \n",
       "2992                    1.4             94.465                 -41.8  0  \n",
       "2993                    1.4             93.444                 -36.1  0  \n",
       "2994                   -1.8             92.893                 -46.2  0  \n",
       "2995                    1.1             93.994                 -36.4  0  \n",
       "2996                   -1.1             94.601                 -49.5  0  \n",
       "2997                   -0.1             93.200                 -42.0  0  \n",
       "2998                   -1.7             94.027                 -38.3  0  \n",
       "\n",
       "[2999 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'have_credit_by_default',\n",
       "       'housing_loan', 'personal_loan', 'communication_type', 'month',\n",
       "       'last_contact_day', 'last_contact_duration', 'no_contact_with_client',\n",
       "       'n_days_clcontact_prev_campaign',\n",
       "       'no_contct_bef_campaign_wth_samepersn', 'employee_variatn_rate',\n",
       "       'consmr_price_indx', 'conmrs_confidnc_indx', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['last_contact_duration'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.get_dummies(data, columns =['job', 'marital', 'have_credit_by_default', 'housing_loan', 'personal_loan', 'communication_type','education','last_contact_day','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>communication_type_cellular</th>\n",
       "      <td>271.0</td>\n",
       "      <td>1664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communication_type_telephone</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal_loan_no</th>\n",
       "      <td>275.0</td>\n",
       "      <td>2162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal_loan_yes</th>\n",
       "      <td>56.0</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have_credit_by_default_no</th>\n",
       "      <td>289.0</td>\n",
       "      <td>2114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have_credit_by_default_unknown</th>\n",
       "      <td>42.0</td>\n",
       "      <td>554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_loan_no</th>\n",
       "      <td>158.0</td>\n",
       "      <td>1252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_loan_yes</th>\n",
       "      <td>173.0</td>\n",
       "      <td>1416.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y                                   1       0\n",
       "communication_type_cellular     271.0  1664.0\n",
       "communication_type_telephone     60.0  1004.0\n",
       "personal_loan_no                275.0  2162.0\n",
       "personal_loan_yes                56.0   506.0\n",
       "have_credit_by_default_no       289.0  2114.0\n",
       "have_credit_by_default_unknown   42.0   554.0\n",
       "housing_loan_no                 158.0  1252.0\n",
       "housing_loan_yes                173.0  1416.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=['communication_type_cellular','communication_type_telephone','personal_loan_no','personal_loan_yes','have_credit_by_default_no','have_credit_by_default_unknown','housing_loan_no','housing_loan_yes']\n",
    "data.groupby(data['y'])[col].sum().sort_values(by=['housing_loan_yes','personal_loan_yes'],ascending=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.y.values\n",
    "X = data.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Try SMOTE tackle the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.datasets import fetch_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96194567 -0.20607401 -0.16516587 ... -0.34621608 -0.13283472\n",
      "  -0.13021098]\n",
      " [-0.08650311  0.57622466 -0.16516587 ... -0.34621608 -0.13283472\n",
      "  -0.13021098]\n",
      " [-1.44830265 -0.59722334 -0.16516587 ... -0.34621608 -0.13283472\n",
      "  -0.13021098]\n",
      " ...\n",
      " [ 1.95619622 -0.20607401 -0.16516587 ... -0.34621608  7.52815229\n",
      "  -0.13021098]\n",
      " [-0.76740288 -0.59722334 -0.16516587 ...  2.88836963 -0.13283472\n",
      "  -0.13021098]\n",
      " [ 2.63709599  0.18507533 -0.16516587 ... -0.34621608 -0.13283472\n",
      "  -0.13021098]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "# use the \"fit_transform\" function to standardize the X design matrix\n",
    "Xs = ss.fit_transform(X)\n",
    "#print(Xs.values)\n",
    "print(Xs)\n",
    "# Standardization is necessary for regularized regression because the beta\n",
    "# values for each predictor variable must be on the same scale. If betas\n",
    "# are different sizes just because of the scale of predictor variables\n",
    "# the regularization term can't determine which betas are more/less \n",
    "# important based on their size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.a Using SMOTE to tackle imbalance dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In each of these cases, only a small fraction of observations are actually positives. Only 10% of the customers opened an account. Recently, oversampling the minority class observations has become a common approach to improve the quality of predictive modeling. By oversampling, models are sometimes better able to learn patterns that differentiate classes. upsample you sample on you train set in a small class .push it in your learning algorthim. predicted on your test. accuracy is not usable. we use auroc to do the model validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y,test_size = .1,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[2398 2398]\n",
      "baseline: 0.5\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n",
    "y_train.shape\n",
    "baseline2= 2398/4796\n",
    "print('baseline:',baseline2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.a. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False  True  True  True False False False  True  True\n",
      " False  True  True False False False False False False False False  True\n",
      " False False  True  True  True False False False False False False False\n",
      " False False False False False  True  True  True  True  True False False]\n",
      "[ 3  1  1 21  1  1  1 17 16  5  1  1 15  1  1  8 11 18  2 31  7 14 23  1\n",
      " 10  6  1  1  1 24 25 29  4  9 19 27 20 30 13 26 28  1  1  1  1  1 22 12]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lg = LogisticRegression()\n",
    "\n",
    "rfe = RFE(lg, 18)\n",
    "rfe = rfe.fit(X_train, y_train )\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733333333333333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logistics_lg=rfe.score(X_test,y_test)\n",
    "Logistics_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>select</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>month_jul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>job_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>housing_loan_no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>no_contact_with_client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>personal_loan_yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>communication_type_cellular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>job_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>job_self-employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>month_jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>job_housemaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>month_mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>month_may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>month_nov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>conmrs_confidnc_indx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>consmr_price_indx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>employee_variatn_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>communication_type_telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>n_days_clcontact_prev_campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>last_contact_day_thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>last_contact_day_fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank  select                        variable\n",
       "41     1    True                       month_jul\n",
       "11     1    True                  job_management\n",
       "23     1    True                 housing_loan_no\n",
       "1      1    True          no_contact_with_client\n",
       "26     1    True               personal_loan_yes\n",
       "27     1    True     communication_type_cellular\n",
       "14     1    True                    job_services\n",
       "13     1    True               job_self-employed\n",
       "42     1    True                       month_jun\n",
       "10     1    True                   job_housemaid\n",
       "43     1    True                       month_mar\n",
       "44     1    True                       month_may\n",
       "45     1    True                       month_nov\n",
       "6      1    True            conmrs_confidnc_indx\n",
       "5      1    True               consmr_price_indx\n",
       "4      1    True           employee_variatn_rate\n",
       "28     1    True    communication_type_telephone\n",
       "2      1    True  n_days_clcontact_prev_campaign\n",
       "35    27   False            last_contact_day_thu\n",
       "33     9   False            last_contact_day_fri"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feature_selection = pd.DataFrame({'variable':X.columns,\n",
    "                            'select':rfe.support_,\n",
    "                            'rank':rfe.ranking_})\n",
    "\n",
    "Feature_selection.sort_values('select', inplace=True, ascending=False)\n",
    "\n",
    "Feature_selection.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rfe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7259259259259259\n"
     ]
    }
   ],
   "source": [
    "#*we will use ROC to check the accuracy, since the datset was imbalance we cant use accuracy as a measurement\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "auc_feat= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7866666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   42.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'solver': ['liblinear'], 'C': array([1.00000e-05, 1.12332e-05, ..., 8.90215e-01, 1.00000e+00])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the parameters. Looking at C regularization strengths on a log scale.\n",
    "# This takes awhile...\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}\n",
    "\n",
    "lr_gridsearch = GridSearchCV(LogisticRegression(), gs_params, cv=5, verbose=1)\n",
    "lr_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7099666388657214"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score on the training data:\n",
    "lr_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.021544346900318846, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters on the training data:\n",
    "lr_gridsearch.best_params_\n",
    "# Ridge was chosen: this indicates that multicolinerity is an issuesb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7933333333333333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign the best estimator to a variable:\n",
    "best_lr = lr_gridsearch.best_estimator_\n",
    "best_lr\n",
    "# Score it on the testing data:\n",
    "lr_Grid=best_lr.score(X_test, y_test)\n",
    "lr_Grid\n",
    "#very good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=best_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "#*we will use ROC to check the accuracy, since the datset was imbalance we cant use accuracy as a measurement\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred2)\n",
    "auc_grid= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "        'coef':best_lr.coef_[0],\n",
    "        'feature':X.columns\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df['abs_coef'] = np.abs(coef_df.coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by absolute value of coefficient (magnitude)\n",
    "coef_df.sort_values('abs_coef', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.803918</td>\n",
       "      <td>employee_variatn_rate</td>\n",
       "      <td>0.803918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.418400</td>\n",
       "      <td>consmr_price_indx</td>\n",
       "      <td>0.418400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.239124</td>\n",
       "      <td>month_may</td>\n",
       "      <td>0.239124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202091</td>\n",
       "      <td>n_days_clcontact_prev_campaign</td>\n",
       "      <td>0.202091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.178415</td>\n",
       "      <td>no_contact_with_client</td>\n",
       "      <td>0.178415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.172401</td>\n",
       "      <td>month_nov</td>\n",
       "      <td>0.172401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.168264</td>\n",
       "      <td>communication_type_cellular</td>\n",
       "      <td>0.168264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.124532</td>\n",
       "      <td>communication_type_telephone</td>\n",
       "      <td>0.124532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.124254</td>\n",
       "      <td>job_management</td>\n",
       "      <td>0.124254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.114535</td>\n",
       "      <td>job_self-employed</td>\n",
       "      <td>0.114535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.106248</td>\n",
       "      <td>personal_loan_yes</td>\n",
       "      <td>0.106248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.099234</td>\n",
       "      <td>month_mar</td>\n",
       "      <td>0.099234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.085472</td>\n",
       "      <td>conmrs_confidnc_indx</td>\n",
       "      <td>0.085472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.069236</td>\n",
       "      <td>housing_loan_no</td>\n",
       "      <td>0.069236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.068131</td>\n",
       "      <td>job_housemaid</td>\n",
       "      <td>0.068131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058888</td>\n",
       "      <td>age</td>\n",
       "      <td>0.058888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.058715</td>\n",
       "      <td>job_services</td>\n",
       "      <td>0.058715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.053825</td>\n",
       "      <td>month_jul</td>\n",
       "      <td>0.053825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.050865</td>\n",
       "      <td>marital_divorced</td>\n",
       "      <td>0.050865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.046761</td>\n",
       "      <td>job_technician</td>\n",
       "      <td>0.046761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef                         feature  abs_coef\n",
       "4  -0.803918           employee_variatn_rate  0.803918\n",
       "5   0.418400               consmr_price_indx  0.418400\n",
       "44 -0.239124                       month_may  0.239124\n",
       "2   0.202091  n_days_clcontact_prev_campaign  0.202091\n",
       "1  -0.178415          no_contact_with_client  0.178415\n",
       "45 -0.172401                       month_nov  0.172401\n",
       "27  0.168264     communication_type_cellular  0.168264\n",
       "28 -0.124532    communication_type_telephone  0.124532\n",
       "11 -0.124254                  job_management  0.124254\n",
       "13 -0.114535               job_self-employed  0.114535\n",
       "26 -0.106248               personal_loan_yes  0.106248\n",
       "43  0.099234                       month_mar  0.099234\n",
       "6   0.085472            conmrs_confidnc_indx  0.085472\n",
       "23  0.069236                 housing_loan_no  0.069236\n",
       "10 -0.068131                   job_housemaid  0.068131\n",
       "0   0.058888                             age  0.058888\n",
       "14 -0.058715                    job_services  0.058715\n",
       "41  0.053825                       month_jul  0.053825\n",
       "18 -0.050865                marital_divorced  0.050865\n",
       "16  0.046761                  job_technician  0.046761"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show non-zero coefs and predictors\n",
    "coef_df[coef_df.coef != 0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# # Create logistic regression\n",
    "# logistic = LogisticRegression()\n",
    "# # Create regularization penalty space\n",
    "# penalty = ['l1', 'l2']\n",
    "\n",
    "# # Create regularization hyperparameter space\n",
    "# C = np.logspace(0, 4, 10)\n",
    "\n",
    "# # Create hyperparameter options\n",
    "# hyperparameters = dict(C=C, penalty=penalty)\n",
    "# # Create grid search using 5-fold cross validation\n",
    "# clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "# # Fit grid search\n",
    "# best_model = clf.fit(X_train, y_train)\n",
    "#  #View best hyperparameters\n",
    "# print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "# print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "# print('Coefficient of each feature:', best_model.best_estimator_.coef_)\n",
    "# print('Training accuracy:', best_model.best_estimator_.score(X_train, y_train))\n",
    "# print('Test accuracy:', best_model.best_estimator_.score(X_test, y_test))\n",
    "# # Predict target vector\n",
    "# #print('Predict target vector',best_model.predict(X_test))\n",
    "# #seems the best algorthm is ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.b Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.00000e+00, 1.05956e+00, ..., 9.43788e+04, 1.00000e+05]),\n",
       "    cv=10, fit_intercept=True, gcv_mode=None, normalize=False,\n",
       "    scoring=None, store_cv_values=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find an optimal value for Ridge regression alpha using RidgeCV\n",
    "ridge_alphas = np.logspace(0, 5, 200)\n",
    "\n",
    "optimal_ridge = RidgeCV(alphas=ridge_alphas, cv=10)\n",
    "optimal_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(optimal_ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.866194309149542"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pred = optimal_ridge.predict(X_test)\n",
    "\n",
    "ridge_score=optimal_ridge.score(X_test, y_test)\n",
    "ridge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.031066302926580747, 'age'),\n",
       " (-0.048996803851151544, 'no_contact_with_client'),\n",
       " (0.016509409471543793, 'n_days_clcontact_prev_campaign'),\n",
       " (-0.0009718912832375794, 'no_contct_bef_campaign_wth_samepersn'),\n",
       " (-0.22836528378055795, 'employee_variatn_rate'),\n",
       " (0.14019604542279843, 'consmr_price_indx'),\n",
       " (0.03410809904705742, 'conmrs_confidnc_indx'),\n",
       " (0.018420646776906354, 'job_admin'),\n",
       " (0.015550797650474645, 'job_blue-collar'),\n",
       " (-0.011145683295874035, 'job_entrepreneur'),\n",
       " (-0.023712144283121805, 'job_housemaid'),\n",
       " (-0.033197011793993904, 'job_management'),\n",
       " (0.0077766923381298566, 'job_retired'),\n",
       " (-0.034355443265049565, 'job_self-employed'),\n",
       " (-0.015041142971700477, 'job_services'),\n",
       " (-0.006761220528347933, 'job_student'),\n",
       " (0.025491349639553854, 'job_technician'),\n",
       " (0.006754134873095973, 'job_unemployed'),\n",
       " (-0.02279815393184428, 'marital_divorced'),\n",
       " (0.0008856588331895486, 'marital_married'),\n",
       " (0.014859247276272478, 'marital_single'),\n",
       " (0.005426783783015637, 'have_credit_by_default_no'),\n",
       " (-0.005426783782977697, 'have_credit_by_default_unknown'),\n",
       " (0.01365795204400619, 'housing_loan_no'),\n",
       " (-0.013657952044021912, 'housing_loan_yes'),\n",
       " (0.015876973865563544, 'personal_loan_no'),\n",
       " (-0.01587697386562574, 'personal_loan_yes'),\n",
       " (0.04096002862034301, 'communication_type_cellular'),\n",
       " (-0.04096002862026812, 'communication_type_telephone'),\n",
       " (-0.0041520630175570245, 'education_basic'),\n",
       " (-0.0042157472697103016, 'education_high.school'),\n",
       " (-0.0007234683954207683, 'education_professional.course'),\n",
       " (0.008540819424917846, 'education_university.degree'),\n",
       " (-0.012308604331451124, 'last_contact_day_fri'),\n",
       " (0.008419010098592384, 'last_contact_day_mon'),\n",
       " (-0.0013378102246950415, 'last_contact_day_thu'),\n",
       " (0.004919713320688015, 'last_contact_day_tue'),\n",
       " (-0.00030558156711520595, 'last_contact_day_wed'),\n",
       " (-0.004906913395799593, 'month_apr'),\n",
       " (0.013831405009329193, 'month_aug'),\n",
       " (0.002639808180572954, 'month_dec'),\n",
       " (0.03702460831369266, 'month_jul'),\n",
       " (0.023413397424242147, 'month_jun'),\n",
       " (0.02013932629919351, 'month_mar'),\n",
       " (-0.03508274072342498, 'month_may'),\n",
       " (-0.03556773157588776, 'month_nov'),\n",
       " (0.0013931389066949437, 'month_oct'),\n",
       " (-0.003479315873977201, 'month_sep')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(optimal_ridge.coef_, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculate the accuracy on the test set and compare to baseline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.866194309149542\n"
     ]
    }
   ],
   "source": [
    "print(optimal_ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778888888888889\n"
     ]
    }
   ],
   "source": [
    "#*we will use ROC to check the accuracy, since the datset was imbalance we cant use accuracy as a measurement\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, ridge_pred)\n",
    "auc_ridge= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.c Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr= LogisticRegression(penalty='l1', C=0.02, solver='liblinear')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Logistic Regression With A L1 Penalty With Various Regularization Strengths\n",
    "The usefulness of L1 is that it can push feature coefficients to 0, creating a method for feature selection. In the code below we run a logistic regression with a L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.02, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_score=lr.score(X_test,y_test)\n",
    "lasso_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred4 = lr.predict(X_test)\n",
    "list(zip(y_pred4,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use ROC as my metric to check performance, since the datset was imbalance we can't use accuracy as a measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7203703703703703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred4)\n",
    "auc_lasso= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test       237\n",
      "y_predict    237\n",
      "dtype: int64 y_test= 300\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['y_test','y_predict'])\n",
    "df.y_test=y_test\n",
    "df.y_predict=y_pred4\n",
    "print(df[df['y_test']==df['y_predict']].count(),'y_test=',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[218  52]\n",
      " [ 11  19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred4)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is telling us that we have 739+1006 correct predictions and 119 incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.05067921, -0.1717701 ,  0.20127266,  0.03133519, -0.78598962,\n",
       "          0.39838761,  0.0769396 ,  0.02949722,  0.        , -0.00572145,\n",
       "         -0.0621932 , -0.11731812,  0.03984486, -0.10661833, -0.05457857,\n",
       "          0.        ,  0.04391484,  0.        , -0.0458372 ,  0.        ,\n",
       "          0.02561828,  0.        ,  0.        ,  0.06682226, -0.0080159 ,\n",
       "          0.01476818, -0.08832523,  0.        , -0.27894931,  0.        ,\n",
       "          0.        ,  0.        ,  0.0068605 , -0.01388176,  0.        ,\n",
       "          0.        ,  0.        ,  0.        , -0.02775719,  0.        ,\n",
       "          0.        ,  0.04655881,  0.04026179,  0.09639358, -0.24451136,\n",
       "         -0.1706368 ,  0.        ,  0.        ]), 'age')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(lr.coef_, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_coef</th>\n",
       "      <th>coef</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.398388</td>\n",
       "      <td>0.398388</td>\n",
       "      <td>consmr_price_indx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.201273</td>\n",
       "      <td>0.201273</td>\n",
       "      <td>n_days_clcontact_prev_campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.096394</td>\n",
       "      <td>0.096394</td>\n",
       "      <td>month_mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.076940</td>\n",
       "      <td>0.076940</td>\n",
       "      <td>conmrs_confidnc_indx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.066822</td>\n",
       "      <td>0.066822</td>\n",
       "      <td>housing_loan_no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050679</td>\n",
       "      <td>0.050679</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.046559</td>\n",
       "      <td>0.046559</td>\n",
       "      <td>month_jul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.043915</td>\n",
       "      <td>0.043915</td>\n",
       "      <td>job_technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.040262</td>\n",
       "      <td>0.040262</td>\n",
       "      <td>month_jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.039845</td>\n",
       "      <td>0.039845</td>\n",
       "      <td>job_retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031335</td>\n",
       "      <td>0.031335</td>\n",
       "      <td>no_contct_bef_campaign_wth_samepersn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.029497</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>job_admin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.025618</td>\n",
       "      <td>0.025618</td>\n",
       "      <td>marital_single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.014768</td>\n",
       "      <td>0.014768</td>\n",
       "      <td>personal_loan_no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.006860</td>\n",
       "      <td>0.006860</td>\n",
       "      <td>education_university.degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>last_contact_day_wed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>last_contact_day_tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>communication_type_cellular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>last_contact_day_thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>last_contact_day_mon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    abs_coef      coef                              variable\n",
       "5   0.398388  0.398388                     consmr_price_indx\n",
       "2   0.201273  0.201273        n_days_clcontact_prev_campaign\n",
       "43  0.096394  0.096394                             month_mar\n",
       "6   0.076940  0.076940                  conmrs_confidnc_indx\n",
       "23  0.066822  0.066822                       housing_loan_no\n",
       "0   0.050679  0.050679                                   age\n",
       "41  0.046559  0.046559                             month_jul\n",
       "16  0.043915  0.043915                        job_technician\n",
       "42  0.040262  0.040262                             month_jun\n",
       "12  0.039845  0.039845                           job_retired\n",
       "3   0.031335  0.031335  no_contct_bef_campaign_wth_samepersn\n",
       "7   0.029497  0.029497                             job_admin\n",
       "20  0.025618  0.025618                        marital_single\n",
       "25  0.014768  0.014768                      personal_loan_no\n",
       "32  0.006860  0.006860           education_university.degree\n",
       "37  0.000000  0.000000                  last_contact_day_wed\n",
       "36  0.000000  0.000000                  last_contact_day_tue\n",
       "27  0.000000  0.000000           communication_type_cellular\n",
       "35  0.000000  0.000000                  last_contact_day_thu\n",
       "34  0.000000  0.000000                  last_contact_day_mon"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coefs = pd.DataFrame({'variable':X.columns,\n",
    "                            'coef':lr.coef_[0],\n",
    "                            'abs_coef':np.abs(lr.coef_[0])})\n",
    "\n",
    "lasso_coefs.sort_values('coef', inplace=True, ascending=False)\n",
    "\n",
    "lasso_coefs.head(20)#lasso_coefs.head(20).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute precision, recall, F-measure and support\n",
    "To quote from Scikit Learn:\n",
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The F-beta score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall and precision are equally important.\n",
    "The support is the number of occurrences of each class in y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.81      0.87       270\n",
      "          1       0.27      0.63      0.38        30\n",
      "\n",
      "avg / total       0.88      0.79      0.82       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usefulness of L1 is that it can push feature coefficients to 0, creating a method for feature selection. In the code below we run a logistic regression with a L1 penalty four times, each time decreasing the value of C. We should expect that as C decreases, more coefficients become 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.d ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "           max_depth=9, max_features='sqrt', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "           oob_score=True, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rfc = ExtraTreesClassifier(bootstrap=True,n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': np.arange(3, 10)\n",
    "    \n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train,y_train)\n",
    "print ('\\n',CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_tree = ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "           max_depth=9, max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
    "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "           max_depth=9, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = ex_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7240740740740741\n"
     ]
    }
   ],
   "source": [
    "#*we will use ROC to check the accuracy, since the datset was imbalance we cant use accuracy as a measurement\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred5)\n",
    "auc_extree= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_extree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test       263\n",
      "y_predict    263\n",
      "dtype: int64 y_test= 300\n"
     ]
    }
   ],
   "source": [
    "#To create a data frmae to show how many target varibales were predicted correctly.\n",
    "df = pd.DataFrame(columns=['y_test','y_predict'])\n",
    "df.y_test=y_test\n",
    "df.y_predict=y_pred5\n",
    "print(df[df['y_test']==df['y_predict']].count(),'y_test=',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.110427</td>\n",
       "      <td>employee_variatn_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.075326</td>\n",
       "      <td>communication_type_cellular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.066203</td>\n",
       "      <td>communication_type_telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.039855</td>\n",
       "      <td>month_may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039223</td>\n",
       "      <td>n_days_clcontact_prev_campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032687</td>\n",
       "      <td>no_contct_bef_campaign_wth_samepersn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.031554</td>\n",
       "      <td>housing_loan_yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.029950</td>\n",
       "      <td>housing_loan_no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.029517</td>\n",
       "      <td>conmrs_confidnc_indx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.029204</td>\n",
       "      <td>marital_single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.026663</td>\n",
       "      <td>month_jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.024339</td>\n",
       "      <td>job_admin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.024110</td>\n",
       "      <td>have_credit_by_default_no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.023676</td>\n",
       "      <td>marital_married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.022714</td>\n",
       "      <td>consmr_price_indx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.021383</td>\n",
       "      <td>have_credit_by_default_unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.020498</td>\n",
       "      <td>education_university.degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.019469</td>\n",
       "      <td>education_basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.019330</td>\n",
       "      <td>last_contact_day_thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.018929</td>\n",
       "      <td>last_contact_day_tue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef                              variable\n",
       "4   0.110427                 employee_variatn_rate\n",
       "27  0.075326           communication_type_cellular\n",
       "28  0.066203          communication_type_telephone\n",
       "44  0.039855                             month_may\n",
       "2   0.039223        n_days_clcontact_prev_campaign\n",
       "3   0.032687  no_contct_bef_campaign_wth_samepersn\n",
       "24  0.031554                      housing_loan_yes\n",
       "23  0.029950                       housing_loan_no\n",
       "6   0.029517                  conmrs_confidnc_indx\n",
       "20  0.029204                        marital_single\n",
       "42  0.026663                             month_jun\n",
       "7   0.024339                             job_admin\n",
       "21  0.024110             have_credit_by_default_no\n",
       "19  0.023676                       marital_married\n",
       "5   0.022714                     consmr_price_indx\n",
       "22  0.021383        have_credit_by_default_unknown\n",
       "32  0.020498           education_university.degree\n",
       "29  0.019469                       education_basic\n",
       "35  0.019330                  last_contact_day_thu\n",
       "36  0.018929                  last_contact_day_tue"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtraTreeClassifier_coefs = pd.DataFrame({'variable':X.columns,\n",
    "                            'coef':ex_tree.feature_importances_,\n",
    "                            })\n",
    "\n",
    "ExtraTreeClassifier_coefs.sort_values('coef', inplace=True, ascending=False)\n",
    "\n",
    "ExtraTreeClassifier_coefs.head(20)#ExtraTreeClassifier_coefs.head(20).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 9,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 200,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': True,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_tree.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Feature ranking:\n",
      "1. feature 4 (0.068222)\n",
      "2. feature 0 (0.046138)\n",
      "3. feature 1 (0.038404)\n",
      "4. feature 24 (0.035090)\n",
      "5. feature 23 (0.035073)\n",
      "6. feature 27 (0.034172)\n",
      "7. feature 6 (0.031591)\n",
      "8. feature 28 (0.031520)\n",
      "9. feature 20 (0.030487)\n",
      "10. feature 19 (0.029963)\n",
      "11. feature 44 (0.028754)\n",
      "12. feature 5 (0.028651)\n",
      "13. feature 34 (0.027272)\n",
      "14. feature 32 (0.027260)\n",
      "15. feature 7 (0.026953)\n",
      "16. feature 36 (0.026857)\n",
      "17. feature 3 (0.025063)\n",
      "18. feature 35 (0.024431)\n",
      "19. feature 37 (0.023528)\n",
      "20. feature 30 (0.023453)\n",
      "21. feature 29 (0.023219)\n",
      "22. feature 2 (0.021747)\n",
      "23. feature 8 (0.021296)\n",
      "24. feature 21 (0.020901)\n",
      "25. feature 33 (0.020656)\n",
      "26. feature 42 (0.019748)\n",
      "27. feature 22 (0.019623)\n",
      "28. feature 31 (0.018497)\n",
      "29. feature 16 (0.017824)\n",
      "30. feature 26 (0.017683)\n",
      "31. feature 25 (0.016996)\n",
      "32. feature 41 (0.015593)\n",
      "33. feature 45 (0.014398)\n",
      "34. feature 39 (0.013346)\n",
      "35. feature 18 (0.012748)\n",
      "36. feature 11 (0.012440)\n",
      "37. feature 14 (0.010339)\n",
      "38. feature 12 (0.009332)\n",
      "39. feature 38 (0.007627)\n",
      "40. feature 43 (0.007277)\n",
      "41. feature 46 (0.006732)\n",
      "42. feature 17 (0.005858)\n",
      "43. feature 47 (0.005601)\n",
      "44. feature 9 (0.005067)\n",
      "45. feature 13 (0.004395)\n",
      "46. feature 15 (0.003741)\n",
      "47. feature 10 (0.003274)\n",
      "48. feature 40 (0.001158)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f34ab5f98>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 260,
       "width": 413
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "# X, y = make_classification(n_samples=1000,\n",
    "#                            n_features=10,\n",
    "#                            n_informative=3,\n",
    "#                            n_redundant=0,\n",
    "#                            n_repeated=0,\n",
    "#                            n_classes=2,\n",
    "#                            random_state=0,\n",
    "#                            shuffle=False)\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=7)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8766666666666667"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_score=ex_tree.score(X_test,y_test)\n",
    "extra_tree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier visualization playground:\n",
    "The purpose of this section is to visualize logistic regression classsifiers’ decision boundaries. In order to better vizualize the decision boundaries, I Will perform Principal Component Analysis (PCA) on the data to reduce the dimensionality to 2 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.e. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN is powerful because it does not assume anything about the data, other than a distance measure can be calculated consistently between any two instances. As such, it is called non-parametric or non-linear as it does not assume a functional form. Lazy learning refers to the fact that the algorithm does not build a model until the time that a prediction is required. It is lazy because it only does work at the last second. This has the benefit of only including data relevant to the unseen data, called a localized model. A disadvantage is that it can be computationally expensive to repeat the same or similar searches over larger training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KNeighborsClassifier from sklearn.neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate from k=1 to k=49 (only odd k) and cross-validate the accuracy of the model for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "# define the parameter values that should be searched\n",
    "k_range = list(range(1, 31))\n",
    "# we create a list\n",
    "weight_options = ['uniform', 'distance']\n",
    "# dictionary = dict(key=values, key=values)\n",
    "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate and fit the grid\n",
    "# exhaustive grid-search because it's trying every combination\n",
    "# 10-fold cross-validation is being performed 30 x 2 = 60 times\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f34a83b38>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 544
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_values = list(range(1,50,2))\n",
    "accs = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10)\n",
    "    accs.append(np.mean(scores))\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(k_values, accs, lw=3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the scores 0.7283237447698745\n"
     ]
    }
   ],
   "source": [
    "print('mean of the scores',np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.4, random_state = 3)\n",
    "knn = KNeighborsClassifier(algorithm='brute',n_neighbors=2,weights= 'uniform')\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculate the accuracy on the test set and compare to baselin*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8433333333333334\n"
     ]
    }
   ],
   "source": [
    "print ('Test accuracy: ', knn.score(X_test, y_test))\n",
    "knn_score=knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the predicted labels and predicted probabilities on the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test class:\n",
    "y_pred6 = knn.predict(X_test)\n",
    "\n",
    "# predicted test probability:\n",
    "y_pp = knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6462962962962963\n"
     ]
    }
   ],
   "source": [
    "#*we will use ROC to check the accuracy, since the datset was imbalance we cant use accuracy as a measurement\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred6)\n",
    "auc_knn= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the confusion matrix for your classfier's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test       232\n",
      "y_predict    232\n",
      "dtype: int64 y_test= 300\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame(columns=['y_test','y_predict'])\n",
    "df3.y_test=y_test\n",
    "df3.y_predict=y_pred\n",
    "print(df3[df3['y_test']==df3['y_predict']].count(),'y_test=',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.f. Random Forest tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f one or a few features are very strong predictors for the response variable (target output), these features will be selected in many of the bagging base trees, causing them to become correlated. By selecting a random subset of the features at each split, we avoid this correlation between base trees, strengthening the overall model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Jasper\\Downloads\\download\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 54}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    " \n",
    "rfc = RandomForestClassifier(bootstrap=True,n_jobs=-1,max_features='sqrt', oob_score = True, random_state=0) \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : [9, 18, 27, 36, 45, 54, 63],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25, 30],\n",
    "           \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]\n",
    "           }\n",
    "    \n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 54}\n"
     ]
    }
   ],
   "source": [
    "print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=54, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_jobs=2, random_state=0,max_depth= 20, min_samples_leaf= 1, n_estimators= 54)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Classifier we trained to the test data (which, remember, it has never seen before)\n",
    "y_pred7=RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [0.63247863, 0.36752137],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94811566, 0.05188434],\n",
       "       [0.9286325 , 0.0713675 ],\n",
       "       [0.9800995 , 0.0199005 ],\n",
       "       [0.82638889, 0.17361111],\n",
       "       [0.90740741, 0.09259259]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the predicted probabilities of the first 10 observations\n",
    "RF.predict_proba(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 0.05489504500783543),\n",
       " ('no_contact_with_client', 0.06767028841230915),\n",
       " ('n_days_clcontact_prev_campaign', 0.04017439022102192),\n",
       " ('no_contct_bef_campaign_wth_samepersn', 0.03791509915728725),\n",
       " ('employee_variatn_rate', 0.0827138534648879),\n",
       " ('consmr_price_indx', 0.04377107072658019),\n",
       " ('conmrs_confidnc_indx', 0.05323989142661248),\n",
       " ('job_admin', 0.02701948406217746),\n",
       " ('job_blue-collar', 0.017914602623164175),\n",
       " ('job_entrepreneur', 0.002919815943695639),\n",
       " ('job_housemaid', 0.001690912520308352),\n",
       " ('job_management', 0.008261722171169099),\n",
       " ('job_retired', 0.006707395160798324),\n",
       " ('job_self-employed', 0.0020770727914502848),\n",
       " ('job_services', 0.008234334200025938),\n",
       " ('job_student', 0.0016651698129854873),\n",
       " ('job_technician', 0.01441215421624427),\n",
       " ('job_unemployed', 0.003157672262930015),\n",
       " ('marital_divorced', 0.010702567252729263),\n",
       " ('marital_married', 0.028386650467177116),\n",
       " ('marital_single', 0.03339245129307141),\n",
       " ('have_credit_by_default_no', 0.020908017066969656),\n",
       " ('have_credit_by_default_unknown', 0.016380674176976803),\n",
       " ('housing_loan_no', 0.03241458774060765),\n",
       " ('housing_loan_yes', 0.030979122299716774),\n",
       " ('personal_loan_no', 0.015928165781198392),\n",
       " ('personal_loan_yes', 0.01978354833968131),\n",
       " ('communication_type_cellular', 0.024367381448491914),\n",
       " ('communication_type_telephone', 0.02634849564281246),\n",
       " ('education_basic', 0.0201927386727734),\n",
       " ('education_high.school', 0.018207735865743317),\n",
       " ('education_professional.course', 0.01610112099707424),\n",
       " ('education_university.degree', 0.02472373328574036),\n",
       " ('last_contact_day_fri', 0.018306848266155574),\n",
       " ('last_contact_day_mon', 0.026879515895049746),\n",
       " ('last_contact_day_thu', 0.021050744710662202),\n",
       " ('last_contact_day_tue', 0.025481771210234365),\n",
       " ('last_contact_day_wed', 0.01889498816383592),\n",
       " ('month_apr', 0.0036962484748751623),\n",
       " ('month_aug', 0.009575408203297723),\n",
       " ('month_dec', 0.000754964989016739),\n",
       " ('month_jul', 0.011098828752856964),\n",
       " ('month_jun', 0.011273780777383587),\n",
       " ('month_mar', 0.002995592305275468),\n",
       " ('month_may', 0.02170856337565419),\n",
       " ('month_nov', 0.010402950246039091),\n",
       " ('month_oct', 0.0031196676272634972),\n",
       " ('month_sep', 0.0015031624901523247)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X,RF.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133333333333333"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_score=RF.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test       274\n",
      "y_predict    274\n",
      "dtype: int64 y_test= 300\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.DataFrame(columns=['y_test','y_predict'])\n",
    "df4.y_test=y_test\n",
    "df4.y_predict=y_pred7\n",
    "print(df4[df4['y_test']==df4['y_predict']].count(),'y_test=',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6851851851851851\n"
     ]
    }
   ],
   "source": [
    "#*we will use ROC to check the accuracy, since the datset was imbalance we cant use accuracy as a measurement\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred7)\n",
    "auc_RF=auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_RF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.g. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*MultinomialNB assumes that features have multinomial distribution which is a generalization of the binomial distribution. Neither binomial nor multinomial distributions can contain negative values. So,I use Gaussian*.\n",
    "It assumes that continuous features follow a normal distribution.\n",
    "There isn't a hyper-parameter to tune, so you have nothing to grid search over(didnt use Grid search).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = X_resampled\n",
    "#Y = y_resampled\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred8 = NB.predict(X_test)\n",
    "y_pred8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([1., 0.]), 'age'),\n",
       " (array([0., 1.]), 'no_contact_with_client'),\n",
       " (array([0., 1.]), 'n_days_clcontact_prev_campaign'),\n",
       " (array([1., 0.]), 'no_contct_bef_campaign_wth_samepersn'),\n",
       " (array([1., 0.]), 'employee_variatn_rate'),\n",
       " (array([1., 0.]), 'consmr_price_indx'),\n",
       " (array([0.9, 0.1]), 'conmrs_confidnc_indx'),\n",
       " (array([0.7, 0.3]), 'job_admin'),\n",
       " (array([1., 0.]), 'job_blue-collar'),\n",
       " (array([0.3, 0.7]), 'job_entrepreneur'),\n",
       " (array([1., 0.]), 'job_housemaid'),\n",
       " (array([1., 0.]), 'job_management'),\n",
       " (array([1., 0.]), 'job_retired'),\n",
       " (array([1., 0.]), 'job_self-employed'),\n",
       " (array([0.9, 0.1]), 'job_services'),\n",
       " (array([1., 0.]), 'job_student'),\n",
       " (array([0.5, 0.5]), 'job_technician'),\n",
       " (array([1., 0.]), 'job_unemployed'),\n",
       " (array([1., 0.]), 'marital_divorced'),\n",
       " (array([1., 0.]), 'marital_married'),\n",
       " (array([1., 0.]), 'marital_single'),\n",
       " (array([0., 1.]), 'have_credit_by_default_no'),\n",
       " (array([1., 0.]), 'have_credit_by_default_unknown'),\n",
       " (array([0.9, 0.1]), 'housing_loan_no'),\n",
       " (array([1., 0.]), 'housing_loan_yes'),\n",
       " (array([1., 0.]), 'personal_loan_no'),\n",
       " (array([1., 0.]), 'personal_loan_yes'),\n",
       " (array([1., 0.]), 'communication_type_cellular'),\n",
       " (array([0., 1.]), 'communication_type_telephone'),\n",
       " (array([1., 0.]), 'education_basic'),\n",
       " (array([0.8, 0.2]), 'education_high.school'),\n",
       " (array([1., 0.]), 'education_professional.course'),\n",
       " (array([1., 0.]), 'education_university.degree'),\n",
       " (array([1., 0.]), 'last_contact_day_fri'),\n",
       " (array([1., 0.]), 'last_contact_day_mon'),\n",
       " (array([0., 1.]), 'last_contact_day_thu'),\n",
       " (array([1., 0.]), 'last_contact_day_tue'),\n",
       " (array([1., 0.]), 'last_contact_day_wed'),\n",
       " (array([1., 0.]), 'month_apr'),\n",
       " (array([1., 0.]), 'month_aug'),\n",
       " (array([0., 1.]), 'month_dec'),\n",
       " (array([1., 0.]), 'month_jul'),\n",
       " (array([1., 0.]), 'month_jun'),\n",
       " (array([1., 0.]), 'month_mar'),\n",
       " (array([1., 0.]), 'month_may'),\n",
       " (array([0., 1.]), 'month_nov'),\n",
       " (array([1., 0.]), 'month_oct'),\n",
       " (array([1., 0.]), 'month_sep')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(NB.predict_proba(X_test).round(1),X.columns))\n",
    "#The columns give the posterior probabilities of the first and second label, respectively. \n",
    "#If you are looking for estimates of uncertainty in your classification, Bayesian approaches like this can be a useful approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8533333333333334"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_score=NB.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[238  32]\n",
      " [ 12  18]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred8)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66041667 0.65416667 0.68125    0.70625    0.68333333 0.71041667\n",
      " 0.675      0.70625    0.68410042 0.68619247]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print((cross_val_score(NB, X_train, y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407407407407408\n"
     ]
    }
   ],
   "source": [
    "#*we will use ROC to check the accuracy, since the datset was imbalance we cant use accuracy as a measurement\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred8)\n",
    "auc_nb= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.h. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 13.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_svm = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'kernel': ['linear','rbf']}\n",
    "svm_gridsearch = GridSearchCV(SVC(), param_grid_svm, cv=5, verbose=1)\n",
    "svm_gridsearch.fit(X_train, y_train)\n",
    "svm_gridsearch.best_params_\n",
    "#it return roc less than 0.6 with kernel :rbf, so i try linear as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm, grid_search\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# def svc_param_selection(X, y, nfolds):\n",
    "#     Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "#     gammas = [0.001, 0.01, 0.1, 1]\n",
    "#     param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "#     grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "#     grid_search.fit(X, y)\n",
    "#     grid_search.best_params_\n",
    "#     return grid_search.best_params_\n",
    "# svc_param_selection(X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM classification object \n",
    "SVM =svm.SVC(kernel='linear', C = 0.001)#the result is much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_score=SVM.score(X_test,y_test)\n",
    "svm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred9=SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test       245\n",
      "y_predict    245\n",
      "dtype: int64 y_test= 300\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.DataFrame(columns=['y_test','y_predict'])\n",
    "df5.y_test=y_test\n",
    "df5.y_predict=y_pred9\n",
    "print(df5[df5['y_test']==df5['y_predict']].count(),'y_test=',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[226  44]\n",
      " [ 11  19]]\n"
     ]
    }
   ],
   "source": [
    "cm_svm = confusion_matrix(y_test, y_pred9)\n",
    "print(cm_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.690625   0.68125    0.69583333 0.69415449 0.70146138]\n"
     ]
    }
   ],
   "source": [
    "scores=cross_val_score(SVM, X_train, y_train, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7351851851851852\n"
     ]
    }
   ],
   "source": [
    "#*we will use ROC to check the accuracy, since the datset was imbalance we cant use accuracy as a measurement\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred9)\n",
    "auc_svm= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.95658009e-02, -8.72309507e-02,  1.05396860e-01,\n",
       "         1.03337221e-01, -4.67554166e-01,  3.72313002e-02,\n",
       "         7.02208797e-02,  5.17913726e-02, -1.05951310e-03,\n",
       "        -2.94427749e-02, -3.00914216e-02, -8.95391226e-02,\n",
       "         6.43443318e-02, -5.03617645e-02, -2.73597470e-02,\n",
       "         5.15095874e-02,  1.49242366e-02,  2.69656658e-02,\n",
       "        -4.97572488e-02,  1.09962937e-04,  3.44044682e-02,\n",
       "         3.40487362e-02, -3.40487362e-02,  3.10885641e-02,\n",
       "        -3.10885641e-02,  3.49571923e-02, -3.49571923e-02,\n",
       "         8.84519134e-02, -8.84519134e-02, -2.13256421e-02,\n",
       "        -2.64030781e-02,  1.36038341e-02,  3.39573348e-02,\n",
       "        -2.99263448e-02,  1.41098751e-02,  1.92343282e-02,\n",
       "        -2.45917702e-04, -4.84950387e-03,  9.96922591e-02,\n",
       "        -3.87175724e-02,  1.13214623e-02,  2.95610949e-02,\n",
       "         1.06932120e-01,  9.38509456e-02, -7.99403015e-02,\n",
       "        -1.48139595e-01,  9.46499903e-02,  5.09200655e-02]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.07956580092341553, 'age'),\n",
       " (-0.08723095071490694, 'no_contact_with_client'),\n",
       " (0.10539686022679268, 'n_days_clcontact_prev_campaign'),\n",
       " (0.10333722139906551, 'no_contct_bef_campaign_wth_samepersn'),\n",
       " (-0.46755416626860313, 'employee_variatn_rate'),\n",
       " (0.037231300246126475, 'consmr_price_indx'),\n",
       " (0.07022087966570972, 'conmrs_confidnc_indx'),\n",
       " (0.05179137262460504, 'job_admin'),\n",
       " (-0.0010595131044698648, 'job_blue-collar'),\n",
       " (-0.029442774925409948, 'job_entrepreneur'),\n",
       " (-0.03009142157425221, 'job_housemaid'),\n",
       " (-0.08953912260923497, 'job_management'),\n",
       " (0.06434433182137796, 'job_retired'),\n",
       " (-0.050361764490897354, 'job_self-employed'),\n",
       " (-0.027359747038167362, 'job_services'),\n",
       " (0.05150958736809126, 'job_student'),\n",
       " (0.014924236603922503, 'job_technician'),\n",
       " (0.026965665780361095, 'job_unemployed'),\n",
       " (-0.04975724875160139, 'marital_divorced'),\n",
       " (0.0001099629367967564, 'marital_married'),\n",
       " (0.034404468206302344, 'marital_single'),\n",
       " (0.034048736210622155, 'have_credit_by_default_no'),\n",
       " (-0.034048736210622155, 'have_credit_by_default_unknown'),\n",
       " (0.031088564126151796, 'housing_loan_no'),\n",
       " (-0.031088564126151796, 'housing_loan_yes'),\n",
       " (0.03495719233661429, 'personal_loan_no'),\n",
       " (-0.03495719233661432, 'personal_loan_yes'),\n",
       " (0.08845191343946118, 'communication_type_cellular'),\n",
       " (-0.08845191343946118, 'communication_type_telephone'),\n",
       " (-0.02132564205068606, 'education_basic'),\n",
       " (-0.026403078146524647, 'education_high.school'),\n",
       " (0.013603834061451534, 'education_professional.course'),\n",
       " (0.03395733478678424, 'education_university.degree'),\n",
       " (-0.02992634478103145, 'last_contact_day_fri'),\n",
       " (0.014109875108121462, 'last_contact_day_mon'),\n",
       " (0.019234328186877654, 'last_contact_day_thu'),\n",
       " (-0.0002459177023077675, 'last_contact_day_tue'),\n",
       " (-0.004849503868813814, 'last_contact_day_wed'),\n",
       " (0.09969225912006079, 'month_apr'),\n",
       " (-0.038717572388881155, 'month_aug'),\n",
       " (0.011321462250393242, 'month_dec'),\n",
       " (0.02956109491530559, 'month_jul'),\n",
       " (0.10693212006100287, 'month_jun'),\n",
       " (0.09385094563229324, 'month_mar'),\n",
       " (-0.07994030150282319, 'month_may'),\n",
       " (-0.14813959455153253, 'month_nov'),\n",
       " (0.09464999027929535, 'month_oct'),\n",
       " (0.050920065466262265, 'month_sep')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(SVM.coef_[0],X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. AUROC comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC means Area Under Curve ; you can calculate the area under various curves though. Common is the ROC curve which is about the tradeoff between true positives and false positives at different thresholds. This AUC value can be used as an evaluation metric, especially when there is *imbalanced classes*.\n",
    "true positive (TP) : predicted to be positive and the actual value is also positive\n",
    "false positive (FP) : predicted to be positive but the actual value is negative\n",
    "true negative (TN) : predicted to be negative and the actual value is also negative\n",
    "false negative (FN) : predicted to be negative but the actual value is positive\n",
    "AUROC NOT  INFLUECNED BY IMBALNCE DATASET AND ACCURACY IS influenced. test of comparison between true positive rate compare to false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUCROC Comparison</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic(Ridge)</th>\n",
       "      <td>0.778889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive_Bayes</th>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.735185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic(lg)</th>\n",
       "      <td>0.725926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTree</th>\n",
       "      <td>0.724074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic(Lasso)</th>\n",
       "      <td>0.720370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.685185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.646296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUCROC Comparison\n",
       "Model                             \n",
       "Logistic(Ridge)           0.778889\n",
       "Naive_Bayes               0.740741\n",
       "SVM                       0.735185\n",
       "Logistic(lg)              0.725926\n",
       "ExtraTree                 0.724074\n",
       "Logistic(Lasso)           0.720370\n",
       "RandomForest              0.685185\n",
       "KNN                       0.646296\n",
       "Baseline                  0.500000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create df with model scores,baseline and AUCROC comparison\n",
    "models = ['Logistic(lg)','Logistic(Lasso)','Logistic(Ridge)','ExtraTree','KNN','RandomForest','SVM','Naive_Bayes','Baseline']#decsiion tree\n",
    "#accuracy =[Logistics_lg,lr_Grid,lasso_score,ridge_score,extra_tree_score,knn_score,random_score,svm_score,naive_bayes_score,baseline2]\n",
    "Roc_comparison = [auc_feat,auc_lasso,auc_ridge,auc_extree,auc_knn,auc_RF,auc_svm,auc_nb,baseline2]\n",
    "class_summary = pd.DataFrame({'Model':models,'AUCROC Comparison':Roc_comparison})#'Best_Model_Score':accuracy,\n",
    "class_summary = class_summary.set_index('Model')\n",
    "#class_summary.groupby('Best Model Score')\n",
    "class_summary.sort_values('AUCROC Comparison', ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "Important_features = pd.DataFrame({'Features':X.columns,\n",
    "                                   \n",
    "                                    'Logistic(Lasso)':lr.coef_[0],\n",
    "                                   'Logistic(Ridge)': optimal_ridge.coef_,\n",
    "                                   'ExtraTree':ex_tree.feature_importances_,\n",
    "                                   'RandomForest':RF.feature_importances_,\n",
    "                                    'SVM':SVM.coef_[0]\n",
    "    \n",
    "                                   \n",
    "                            \n",
    "                                  \n",
    "                                  })\n",
    "Important_features=Important_features.set_index('Features')\n",
    "#class_summary = pd.DataFrame({'Model':models,'Column_names:':Columns_names1,'Features':Features})#'Best_Model_Score':accuracy,\n",
    "#class_summary = class_summary.set_index('Model')\n",
    "#class_summary.groupby('Best Model Score')\n",
    "#class_summary.sort_values('Features', ascending =False)\n",
    "\n",
    "Important_features.sort_values('Logistic(Ridge)',inplace=True,  ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the important features for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtraTree</th>\n",
       "      <th>Logistic(Lasso)</th>\n",
       "      <th>Logistic(Ridge)</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>consmr_price_indx</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communication_type_cellular</th>\n",
       "      <td>0.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_jul</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conmrs_confidnc_indx</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_technician</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_jun</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_mar</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_admin</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_days_clcontact_prev_campaign</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal_loan_no</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_blue-collar</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_single</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_aug</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_loan_no</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_university.degree</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_contact_day_mon</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_retired</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_unemployed</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have_credit_by_default_no</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ExtraTree  Logistic(Lasso)  Logistic(Ridge)  \\\n",
       "Features                                                                      \n",
       "consmr_price_indx                   0.023            0.398            0.140   \n",
       "communication_type_cellular         0.075            0.000            0.041   \n",
       "month_jul                           0.013            0.047            0.037   \n",
       "conmrs_confidnc_indx                0.030            0.077            0.034   \n",
       "age                                 0.010            0.051            0.031   \n",
       "job_technician                      0.009            0.044            0.025   \n",
       "month_jun                           0.027            0.040            0.023   \n",
       "month_mar                           0.013            0.096            0.020   \n",
       "job_admin                           0.024            0.029            0.018   \n",
       "n_days_clcontact_prev_campaign      0.039            0.201            0.017   \n",
       "personal_loan_no                    0.017            0.015            0.016   \n",
       "job_blue-collar                     0.017            0.000            0.016   \n",
       "marital_single                      0.029            0.026            0.015   \n",
       "month_aug                           0.012            0.000            0.014   \n",
       "housing_loan_no                     0.030            0.067            0.014   \n",
       "education_university.degree         0.020            0.007            0.009   \n",
       "last_contact_day_mon                0.017            0.000            0.008   \n",
       "job_retired                         0.011            0.040            0.008   \n",
       "job_unemployed                      0.005            0.000            0.007   \n",
       "have_credit_by_default_no           0.024            0.000            0.005   \n",
       "\n",
       "                                RandomForest    SVM  \n",
       "Features                                             \n",
       "consmr_price_indx                      0.044  0.037  \n",
       "communication_type_cellular            0.024  0.088  \n",
       "month_jul                              0.011  0.030  \n",
       "conmrs_confidnc_indx                   0.053  0.070  \n",
       "age                                    0.055  0.080  \n",
       "job_technician                         0.014  0.015  \n",
       "month_jun                              0.011  0.107  \n",
       "month_mar                              0.003  0.094  \n",
       "job_admin                              0.027  0.052  \n",
       "n_days_clcontact_prev_campaign         0.040  0.105  \n",
       "personal_loan_no                       0.016  0.035  \n",
       "job_blue-collar                        0.018 -0.001  \n",
       "marital_single                         0.033  0.034  \n",
       "month_aug                              0.010 -0.039  \n",
       "housing_loan_no                        0.032  0.031  \n",
       "education_university.degree            0.025  0.034  \n",
       "last_contact_day_mon                   0.027  0.014  \n",
       "job_retired                            0.007  0.064  \n",
       "job_unemployed                         0.003  0.027  \n",
       "have_credit_by_default_no              0.021  0.034  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort_values(by=['Logistic(Ridge)'],inplace=True,  ascending=False)\n",
    "Important_features[Important_features['Logistic(Ridge)'] > 0].head(20).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features\n",
       "consmr_price_indx                 0.140\n",
       "communication_type_cellular       0.041\n",
       "month_jul                         0.037\n",
       "conmrs_confidnc_indx              0.034\n",
       "age                               0.031\n",
       "job_technician                    0.025\n",
       "month_jun                         0.023\n",
       "month_mar                         0.020\n",
       "job_admin                         0.018\n",
       "n_days_clcontact_prev_campaign    0.017\n",
       "personal_loan_no                  0.016\n",
       "job_blue-collar                   0.016\n",
       "marital_single                    0.015\n",
       "month_aug                         0.014\n",
       "housing_loan_no                   0.014\n",
       "education_university.degree       0.009\n",
       "last_contact_day_mon              0.008\n",
       "job_retired                       0.008\n",
       "job_unemployed                    0.007\n",
       "have_credit_by_default_no         0.005\n",
       "Name: Logistic(Ridge), dtype: float64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Important_features['Logistic(Ridge)'][Important_features['Logistic(Ridge)'] > 0].head(20).round(3).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features\n",
       "consmr_price_indx                       0.398\n",
       "n_days_clcontact_prev_campaign          0.201\n",
       "month_mar                               0.096\n",
       "conmrs_confidnc_indx                    0.077\n",
       "housing_loan_no                         0.067\n",
       "age                                     0.051\n",
       "month_jul                               0.047\n",
       "job_technician                          0.044\n",
       "job_retired                             0.040\n",
       "month_jun                               0.040\n",
       "no_contct_bef_campaign_wth_samepersn    0.031\n",
       "job_admin                               0.029\n",
       "marital_single                          0.026\n",
       "personal_loan_no                        0.015\n",
       "education_university.degree             0.007\n",
       "Name: Logistic(Lasso), dtype: float64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Important_features['Logistic(Lasso)'][Important_features['Logistic(Lasso)'] > 0].head(20).round(3).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features\n",
       "month_jun                         0.107\n",
       "n_days_clcontact_prev_campaign    0.105\n",
       "month_oct                         0.095\n",
       "month_mar                         0.094\n",
       "communication_type_cellular       0.088\n",
       "age                               0.080\n",
       "conmrs_confidnc_indx              0.070\n",
       "job_retired                       0.064\n",
       "job_admin                         0.052\n",
       "consmr_price_indx                 0.037\n",
       "personal_loan_no                  0.035\n",
       "marital_single                    0.034\n",
       "have_credit_by_default_no         0.034\n",
       "education_university.degree       0.034\n",
       "housing_loan_no                   0.031\n",
       "month_jul                         0.030\n",
       "job_unemployed                    0.027\n",
       "job_technician                    0.015\n",
       "last_contact_day_mon              0.014\n",
       "month_dec                         0.011\n",
       "Name: SVM, dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Important_features['SVM'][Important_features['SVM'] > 0].head(20).round(3).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features\n",
       "communication_type_cellular       0.075\n",
       "n_days_clcontact_prev_campaign    0.039\n",
       "conmrs_confidnc_indx              0.030\n",
       "housing_loan_no                   0.030\n",
       "marital_single                    0.029\n",
       "month_jun                         0.027\n",
       "job_admin                         0.024\n",
       "have_credit_by_default_no         0.024\n",
       "consmr_price_indx                 0.023\n",
       "education_university.degree       0.020\n",
       "job_blue-collar                   0.017\n",
       "personal_loan_no                  0.017\n",
       "last_contact_day_mon              0.017\n",
       "month_mar                         0.013\n",
       "month_jul                         0.013\n",
       "month_aug                         0.012\n",
       "job_retired                       0.011\n",
       "age                               0.010\n",
       "job_technician                    0.009\n",
       "job_unemployed                    0.005\n",
       "Name: ExtraTree, dtype: float64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Important_features['ExtraTree'][Important_features['ExtraTree'] > 0].head(20).round(3).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features\n",
       "age                               0.055\n",
       "conmrs_confidnc_indx              0.053\n",
       "consmr_price_indx                 0.044\n",
       "n_days_clcontact_prev_campaign    0.040\n",
       "marital_single                    0.033\n",
       "housing_loan_no                   0.032\n",
       "job_admin                         0.027\n",
       "last_contact_day_mon              0.027\n",
       "education_university.degree       0.025\n",
       "communication_type_cellular       0.024\n",
       "have_credit_by_default_no         0.021\n",
       "job_blue-collar                   0.018\n",
       "personal_loan_no                  0.016\n",
       "job_technician                    0.014\n",
       "month_jun                         0.011\n",
       "month_jul                         0.011\n",
       "month_aug                         0.010\n",
       "job_retired                       0.007\n",
       "job_unemployed                    0.003\n",
       "month_mar                         0.003\n",
       "Name: RandomForest, dtype: float64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Important_features['RandomForest'][Important_features['RandomForest'] > 0].head(20).round(3).sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
