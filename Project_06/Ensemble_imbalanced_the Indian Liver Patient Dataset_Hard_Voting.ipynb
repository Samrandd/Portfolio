{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise, we'll work with the Indian Liver Patient Dataset from the Kaggle.\n",
    "In this exercise, we'll instantiate three classifiers and different decidion tree algorithms to predict whether a patient suffers from a liver disease using all the features present in the dataset.\n",
    "\n",
    "The classes are LogisticRegression, DecisionTreeClassifier, and KNeighborsClassifier u.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import function to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Indian Liver Patient Dataset (ILPD).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      "age                 583 non-null int64\n",
      "gender              583 non-null object\n",
      "tot_bilirubin       583 non-null float64\n",
      "direct_bilirubin    583 non-null float64\n",
      "tot_proteins        583 non-null int64\n",
      "albumin             583 non-null int64\n",
      "ag_ratio            583 non-null int64\n",
      "sgpt                583 non-null float64\n",
      "sgot                583 non-null float64\n",
      "alkphos             579 non-null float64\n",
      "is_patient          583 non-null int64\n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'gender', 'tot_bilirubin', 'direct_bilirubin', 'tot_proteins',\n",
       "       'albumin', 'ag_ratio', 'sgpt', 'sgot', 'alkphos', 'is_patient'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gender=data.gender.map(lambda x: 0 if x == 'Male' else 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "gender              0\n",
       "tot_bilirubin       0\n",
       "direct_bilirubin    0\n",
       "tot_proteins        0\n",
       "albumin             0\n",
       "ag_ratio            0\n",
       "sgpt                0\n",
       "sgot                0\n",
       "alkphos             4\n",
       "is_patient          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.alkphos.fillna(data.alkphos.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.is_patient.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    416\n",
       "2    167\n",
       "Name: is_patient, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_patient.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.713551\n",
       "2    0.286449\n",
       "Name: is_patient, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_patient.value_counts(normalize=True)\n",
    "#Since the data is not balanced((71% to 21% ), we need to use Smote technnique solve the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('is_patient',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs=ss.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.datasets import fetch_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve,auc,accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y,test_size = .2,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercises we'll revisit the Indian Liver Patient dataset which was introduced in a previous chapter. Our task is to predict whether a patient suffers from a liver disease using 10 features including Albumin, age and gender. In addition, given that this dataset is imbalanced, we'll be using the ROC AUC score as a metric instead of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samra\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[328 328]\n",
      "baseline: [0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n",
    "y_train.shape\n",
    "baseline2= counts/(counts*2)\n",
    "print('baseline:',baseline2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is imbalanced, we may need to use GRIDsearch to find the best measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=0.4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=0.04, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dt1 = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "#Define the grid of hyperparameters 'params_dt'\n",
    "params_dt = {\n",
    "                     'max_depth': [3, 4,5, 6],\n",
    "                     'min_samples_leaf': [0.04, 0.06, 0.08],\n",
    "                     'max_features': [0.2, 0.4,0.6, 0.8]\n",
    "                     }\n",
    "# Instantiate a 10-fold CV grid search object 'grid_dt'\n",
    "#grid_dt = GridSearchCV (estimator=dt1,  param_grid=params_dt, scoring='accuracy', cv=10, n_jobs=-1)            \n",
    "                              \n",
    "grid_dt = GridSearchCV (estimator=dt1,  param_grid=params_dt,cv=10, n_jobs=-1) \n",
    "                               \n",
    "grid_dt.fit(X_test,y_test)\n",
    "y_pred=grid_dt.predict(X_test)\n",
    "# Extract best model from 'grid_dt'\n",
    "grid_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'max_features': 0.4, 'min_samples_leaf': 0.04}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_h = DecisionTreeClassifier(max_depth= 3, max_features= 0.4, min_samples_leaf= 0.04,criterion='gini', random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Tree : 0.670\n"
     ]
    }
   ],
   "source": [
    "dt_h.fit(X_train,y_train)    \n",
    "# Predict y_pred\n",
    "y_pred = dt_h.predict(X_test)\n",
    "# Calculate accuracy\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred,pos_label=2)#pos_label when the patient is not sick\n",
    "accuracy_ROC= auc(fp_rate, tp_rate,'\\n')\n",
    "# Evaluate clf's accuracy on the test set\n",
    "print('{:s} : {:.3f}'.format(clf_name, accuracy_ROC))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit improvement in Roc score, but Logistics seems still win.\n",
    "We may to do the Grid search for Logistics regression as well to see if we can get a better ROC score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.10974987654930568, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the parameters. Looking at C regularization strengths on a log scale.\n",
    "# This takes awhile...\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}\n",
    "\n",
    "lr_gridsearch = GridSearchCV(LogisticRegression(), gs_params, cv=5, verbose=1)\n",
    "lr_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# best score on the training data:\n",
    "lr_gridsearch.best_score_\n",
    "# best parameters on the training data:\n",
    "lr_gridsearch.best_params_\n",
    "# Ridge was chosen: this indicates that multicolinerity is an issuesb\n",
    "# assign the best estimator to a variable:\n",
    "best_lr = lr_gridsearch.best_estimator_\n",
    "best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ideal =LogisticRegression(C=0.10974987654930568, class_weight=None, dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2',solver='liblinear', tol=0.0001, verbose=0, warm_start=False,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_lr 0.670\n"
     ]
    }
   ],
   "source": [
    "lr_ideal.fit(X_train,y_train)    \n",
    "# Predict y_pred\n",
    "y_pred_lr = lr_ideal.predict(X_test)\n",
    "# Calculate accuracy\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred,pos_label=2)#pos_label when the patient is not sick\n",
    "accuracy_ROC_lr= auc(fp_rate, tp_rate,'\\n')\n",
    "# Evaluate lr's accuracy on the test set\n",
    "print('accuracy_lr {:.3f}'.format(accuracy_ROC_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the parameter values that should be searched\n",
    "k_range = list(range(1, 31))\n",
    "# we create a list\n",
    "weight_options = ['uniform', 'distance']\n",
    "# dictionary = dict(key=values, key=values)\n",
    "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(param_grid)\n",
    "#instantiate and fit the grid\n",
    "# exhaustive grid-search because it's trying every combination\n",
    "# 10-fold cross-validation is being performed 30 x 2 = 60 times\n",
    "\n",
    "grid_knn = GridSearchCV(KNN(), param_grid, cv=10, )\n",
    "grid_knn.fit(X_train, y_train)\n",
    "grid_knn.best_params_\n",
    "grid_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of k is 1 may lead to overfitting, so we may need to do the cross validation to find the bette value for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAEyCAYAAADX3IgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8lOW99/HPLxthC2sgCWGVTXYrbqhgrVZQK+2pWjinrfZ4jnrUPq1H22p7np4ez/E8rW21m12stYu2WrVaURHEBRdABZR9DSAQEpKwLyFk+z1/zDBMQkImySQzk/m+X6+8nPueazK/3JJ8577u674uc3dEREQk/qXEugARERGJjEJbREQkQSi0RUREEoRCW0REJEEotEVERBKEQltERCRBKLRFREQShEJbREQkQSi0RUREEkRarAuor2/fvj5kyJBYlyEiItJuli9fvsfds5tqF3ehPWTIEJYtWxbrMkRERNqNmW2PpJ26x0VERBKEQltERCRBKLRFREQShEJbREQkQSi0RUREEoRCW0REJEEotEVERBKEQltERCRBdOjQrq6pZee+chYV7KGqpjbW5YiIiLRK3M2IFk2X/GghhfuPAbDw7ksY0rdrjCsSERFpuQ59pp3Xo3Po8Y595TGsREREpPU6dGgP7N0l9HjnfoW2iIgktg4e2jrTFhGRjqNDh/agsDPtwn3HYliJiIhI63Xo0A7vHteZtoiIJLoOHdqDdE1bREQ6kA4d2tndOpGRFvgRD5RXcaiiKsYViYiItFyHDu2UFGNgr5OD0Xaqi1xERBJYhw5tqHfbl0JbREQSWIcP7TrXtTWCXEREEliHD+2BvTSCXEREOoaOH9oaQS4iIh1EEoS2ZkUTEZGOIQlCO2xWtP3HqK31GFYjIiLSch0+tLMy0+nZJR2AyupaSg8fj3FFIiIiLdPhQxs0M5qIiHQMSRHadUaQ71Voi4hIYkqO0NaZtoiIdABJEtoaQS4iIokvKUJb62qLiEhHkBShrVnRRESkI4gotM1supltNLMCM7ungecHmdmbZvaRma0ysyvDnrs3+LqNZnZFNIuPVF7PzqRY4HHJ4QoqqmpiUYaIiEirNBnaZpYKPAzMAMYAs81sTL1m/wE87e5nAbOAXwZfOya4PRaYDvwy+P3aVUZaCrk9Ate13WHXAXWRi4hI4onkTPtcoMDdt7p7JfAUMLNeGweygo97AEXBxzOBp9z9uLtvAwqC36/dhQ9G0xKdIiKSiCIJ7QHAzrDtwuC+cN8DvmhmhcBc4KvNeC1mdrOZLTOzZWVlZRGW3jzh17UV2iIikogiCW1rYF/9CbxnA39w93zgSuBxM0uJ8LW4+yPuPtndJ2dnZ0dQUvPVnRVN3eMiIpJ40iJoUwgMDNvO52T39wk3EbhmjbsvMbNMoG+Er20X4ROsaFY0ERFJRJGcaS8FRpjZUDPLIDCwbE69NjuATwGY2ZlAJlAWbDfLzDqZ2VBgBPBBtIpvDs2KJiIiia7JM213rzazO4D5QCrwmLuvNbP7gGXuPge4C/itmd1JoPv7Rnd3YK2ZPQ2sA6qB2909JvdbaVY0ERFJdJF0j+PucwkMMAvf992wx+uACxt57f3A/a2oMSqyu3UiMz2FiqpaDldUc7C8ih7BJTtFREQSQVLMiAZgZpoZTUREElrShDZoXW0REUlsSRXadUaQ60xbREQSTNKGtiZYERGRRJNcod1LI8hFRCRxJVVoD+oTtq62ZkUTEZEEk1ShHT56vHB/OTW1p8yoKiIiEreSKrS7dkqjT9cMAKpqnJJDFTGuSEREJHJJFdoA+RpBLiIiCSrpQnuQRpCLiEiCSrrQDh9BriU6RUQkkSRdaOtMW0REElXShbYmWBERkUSVdKE9SAPRREQkQSVdaOf2yCQ1xQAoPXyciqqYLO8tIiLSbEkX2mmpKeT1zAxtF2q1LxERSRBJF9pQd2a0nfs0glxERBJD0oe2rmuLiEiiSMrQDl84RCPIRUQkUSRlaOdriU4REUlASRnadSZY0axoIiKSIJIytOtPsOKuJTpFRCT+JWVo9+maQZeMVACOHK/mQHlVjCsSERFpWlKGtplpBLmIiCScpAxtqNdFrglWREQkASRxaGsEuYiIJJakDe26S3RqBLmIiMS/pA3tulOZ6kxbRETiX0ShbWbTzWyjmRWY2T0NPP+Qma0Ifm0yswNhzz1gZmvNbL2Z/czMLJo/QEvVmRVN17RFRCQBpDXVwMxSgYeBy4FCYKmZzXH3dSfauPudYe2/CpwVfDwFuBCYEHz6XWAasDBK9bdY+Kxou/Yfo6bWQ0t2ioiIxKNIzrTPBQrcfau7VwJPATNP03428GTwsQOZQAbQCUgHSlpebvR0yUijb7dOAFTXOsUHdV1bRETiWyShPQDYGbZdGNx3CjMbDAwF3gBw9yXAm0Bx8Gu+u69vTcHRpBHkIiKSSCIJ7Yb6jBub93MW8Ky71wCY2XDgTCCfQNBfamZTT3kDs5vNbJmZLSsrK4us8igIH0FeqBHkIiIS5yIJ7UJgYNh2PlDUSNtZnOwaB/gc8J67H3H3I8ArwPn1X+Tuj7j7ZHefnJ2dHVnlUaBZ0UREJJFEEtpLgRFmNtTMMggE85z6jcxsFNALWBK2ewcwzczSzCydwCC0uOkeH6RZ0UREJIE0GdruXg3cAcwnELhPu/taM7vPzK4JazobeMrrLpn1LLAFWA2sBFa6+4tRq76V8nVNW0REEkiTt3wBuPtcYG69fd+tt/29Bl5XA9zSivralGZFExGRRJK0M6IB5PboTFrw3uw9R45TXlkd44pEREQal9ShnZpiDAibZKVwv862RUQkfiV1aEO9EeR7dV1bRETil0JbI8hFRCRBKLQ1glxERBJE0oe2RpCLiEiiSPrQ1rraIiKSKJI+tOvPilZ3bhgREZH4kfSh3bNLOt06BeaYKa+sYe/RyhhXJCIi0rCkD20zqzuCXF3kIiISp5I+tAEG9tIIchERiX8Kbeqtq61Z0UREJE4ptKk7wYpmRRMRkXil0EbraouISGJQaFN3VjSFtoiIxCuFNpAfNsFK0YEKqmtqY1iNiIhIwxTaQGZ6Kv26dwKgptYpPlgR44pEREROpdAOCr+urdu+REQkHim0gzTBioiIxDuFdtBAnWmLiEicU2gHhc+KtlMTrIiISBxSaAfpmraIiMQ7hXZQePd4oUJbRETikEI7qH9WJhmpgcOx92glR49Xx7giERGRuhTaQakpxoBemhlNRETil0I7jBYOERGReKbQDqMR5CIiEs8U2mEGaYIVERGJYwrtMJoVTURE4llEoW1m081so5kVmNk9DTz/kJmtCH5tMrMDYc8NMrNXzWy9ma0zsyHRKz+6dK+2iIjEs7SmGphZKvAwcDlQCCw1sznuvu5EG3e/M6z9V4Gzwr7Fn4D73X2BmXUD4nbdy4FhS3Tu3F+Ou2NmMaxIRETkpEjOtM8FCtx9q7tXAk8BM0/TfjbwJICZjQHS3H0BgLsfcfe4PYXt0SWdrMzA55iKqlrKjhyPcUUiIiInRRLaA4CdYduFwX2nMLPBwFDgjeCukcABM3vOzD4ysx8Gz9zrv+5mM1tmZsvKysqa9xNEWd3r2hpBLiIi8SOS0G6of9gbaTsLeNbda4LbacDFwN3AOcAw4MZTvpn7I+4+2d0nZ2dnR1BS29EIchERiVeRhHYhMDBsOx8oaqTtLIJd42Gv/SjYtV4N/B34REsKbS8aQS4iIvEqktBeCowws6FmlkEgmOfUb2Rmo4BewJJ6r+1lZidOny8F1tV/bTzRutoiIhKvmgzt4BnyHcB8YD3wtLuvNbP7zOyasKazgafc3cNeW0Oga/x1M1tNoKv9t9H8AaJtoOYfFxGRONXkLV8A7j4XmFtv33frbX+vkdcuACa0sL52p4FoIiISrzQjWj0DenbmxK3ZxQePUVkdt7eVi4hIklFo15OZnkr/7pkA1DoUHdDZtoiIxAeFdgPq3Pal69oiIhInFNoNyO99cjCaRpCLiEi8UGg3YJAGo4mISBxSaDegzsIhOtMWEZE4odBuwKA+uqYtIiLxR6HdgPAzbV3TFhGReKHQbkC/7p3ISAscmgPlVRyqqIpxRSIiIgrtBqWkGPnh05nqbFtEROKAQrsRGkEuIiLxRqHdCI0gFxGReKPQboRmRRMRkXij0G7EQM2KJiIicUah3Yi6S3QqtEVEJPYU2o2oE9r7j1Fb6zGsRkRERKHdqKzMdHp2SQegsrqWsiPHY1yRiIgkO4X2aWgEuYiIxBOF9mmEjyDXYDQREYk1hfZphK+rrQlWREQk1hTap6EzbRERiScK7dOoc01bE6yIiEiMKbRPY5Du1RYRkTii0D6NvJ6dMQs83n2oguPVNbEtSEREkppC+zQy0lLI6xEYjOYOW0qPxrgiERFJZgrtJkwa1DP0+N2CshhWIiIiyU6h3YRpI7JDj9/apNAWEZHYUWg3YerIk6G9dNt+yiurY1iNiIgkM4V2E3J6ZDKqf3cAKmtqeW/r3hhXJCIiySqi0Daz6Wa20cwKzOyeBp5/yMxWBL82mdmBes9nmdkuM/tFtApvT9NGhXWRb1QXuYiIxEaToW1mqcDDwAxgDDDbzMaEt3H3O919krtPAn4OPFfv2/w38FZ0Sm5/U8Oua7+9eU8MKxERkWQWyZn2uUCBu29190rgKWDmadrPBp48sWFmZwP9gVdbU2gsTR7Si87pqQBs23OUHXs10YqIiLS/SEJ7ALAzbLswuO8UZjYYGAq8EdxOAX4MfON0b2BmN5vZMjNbVlYWf93PmempXHBGn9D2W5vjr0YREen4Iglta2CfN9J2FvCsu5+YOuw2YK6772ykfeCbuT/i7pPdfXJ2dvbpmsbM1BF9Q491XVtERGIhLYI2hcDAsO18oKiRtrOA28O2LwAuNrPbgG5AhpkdcfdTBrPFu2mj+sGL6wBYsmUPldW1ZKRp8L2IiLSfSFJnKTDCzIaaWQaBYJ5Tv5GZjQJ6AUtO7HP3f3L3Qe4+BLgb+FMiBjbAkD5dGBhcX/toZQ3Lt++PcUUiIpJsmgxtd68G7gDmA+uBp919rZndZ2bXhDWdDTzl7o11nSc0M2PaSM2OJiIisWPxlrGTJ0/2ZcuWxbqMBr26djc3P74cgDG5Wcz92sUxrkhERDoCM1vu7pObaqeLss0wZXhf0lIC4/LWFR+i9HBFjCsSEZFkotBuhm6d0pg8pFdo+51NmmhFRETaj0K7mabquraIiMSIQruZwgejvbO5jJra+BoTICIiHZdCu5nOzMmib7dOAOwvr2LNroMxrkhERJKFQruZUlKMqSPDZkdTF7mIiLQThXYLhHeRv63QFhGRdqLQboGLhvfFgjOyf7TzAAePVcW2IBERSQoK7Rbo060T4wf0AKCm1llcoFu/RESk7Sm0W0hTmoqISHtTaLdQ/eva8TYdrIiIdDwK7RaaNLAn3TMDK5sWHaygoPRIjCsSEZGOTqHdQmmpKVw0XLd+iYhI+1Fot4KmNBURkfak0G6F8NB+f9s+jlXWxLAaERHp6BTarTCgZ2eG9+sGQGV1Le9v2xvjikREpCNTaLeSbv0SEZH2otBupama0lRERNqJQruVzhvam05pgcO4pewohfvLY1yRiIh0VArtVspMT+X8YX1C229v0pSmIiLSNhTaUVD31q/SGFYiIiIdmUI7CsIHoy0u2EtVTW0MqxERkY5KoR0FZ2R3ZUDPzgAcPl7NRzsOxLgiERHpiBTaUWBm6iIXEZE2p9COkmkjT85DrsFoIiLSFhTaUTJleF9SUwyA1bsOsufI8RhXJCIiHY1CO0qyMtM5e1Cv0Pa7m3W2LSIi0aXQjqKpI7VUp4iItB2FdhRNG9kv9PidzWXU1noMqxERkY4motA2s+lmttHMCszsngaef8jMVgS/NpnZgeD+SWa2xMzWmtkqM/tCtH+AeDI2L4s+XTMA2HOkknXFh2JckYiIdCRNhraZpQIPAzOAMcBsMxsT3sbd73T3Se4+Cfg58FzwqXLgy+4+FpgO/MTMekbzB4gnKSnGxSPURS4iIm0jkjPtc4ECd9/q7pXAU8DM07SfDTwJ4O6b3H1z8HERUApkn+a1CW+qluoUEZE2EkloDwB2hm0XBvedwswGA0OBNxp47lwgA9jSwHM3m9kyM1tWVpbYQXfxiJOh/eH2/RyuqIphNSIi0pFEEtrWwL7GRljNAp5195o638AsF3gc+Iq7nzIxt7s/4u6T3X1ydnZin4hnd+/E2LwsAKprncVb9sa4IhER6SgiCe1CYGDYdj5Q1EjbWQS7xk8wsyzgZeA/3P29lhSZaKapi1xERNpAJKG9FBhhZkPNLINAMM+p38jMRgG9gCVh+zKA54E/ufsz0Sk5/oWH9tubynDXrV8iItJ6TYa2u1cDdwDzgfXA0+6+1szuM7NrwprOBp7yugl1PTAVuDHslrBJUaw/Ln1icC+6dUoDoHD/MbbuORrjikREpCNIi6SRu88F5tbb9916299r4HVPAE+0or6ElJ6awpQz+vDquhIgcLZ9Rna3GFclIiKJTjOitRHd+iUiItGm0G4j4de139u6l4qqmtO0FhERaZpCu40M7N2FYX27AlBRVcvSj/fFuCIREUl0Cu02VKeLfKO6yEVEpHUU2m2ozq1fmxXaIiLSOgrtNnTesN5kpAUO8aaSIxQdOBbjikREJJEptNtQl4w0zhvaO7T9js62RUSkFRTabWzqCN36JSIi0aHQbmPTRp0M7Xc276G8sjqG1YiISCJTaLexEf26MbB3ZwAOV1Tz+0Ufx7YgERFJWArtNmZm3H7J8ND2rxduYf/RyhhWJCIiiUqh3Q6uPTufM7IDE60cPl7Nw28WxLgiERFJRArtdpCWmsI3rhgd2v7Tku0U7i+PYUUiIpKIFNrt5Iqx/TlrUE8AKmtqeXDBphhXJCIiiUah3U7MjHumnzzbfv6jXWzYfSiGFYmISKJRaLej84b14dLR/QBwhwfmbYxxRSIikkgU2u3sm9NHYRZ4/MaGUt7fuje2BYmISMJQaLez0TlZ/MNZ+aHt78/bgLvHsCIREUkUCu0YuPPyEWSkBg79RzsOMH9tSYwrEhGRRKDQjoH8Xl348gWDQ9sPzN9AdU1tDCsSEZFEoNCOkds/OZzundIA2Fp2lGeXF8a4IhERiXcK7Rjp1TWDWy85I7T90GubOFZZE8OKREQk3im0Y+grFw6hX/dOAJQcOs7vF2+LcUUiIhLPFNox1CUjja9fNjK0/auFWzhQrsVERESkYQrtGLt+cj7D+gYXE6mo5pcLt8S4orZXXlnNniPHY12GiEjCUWjHWGAxkVGh7T8s/phdB47FsKK2UV5ZzYsri7jl8WVMum8Bk//nNe59bjVHjlfHujQRkYSRFusCBKaPy2HiwJ6s3HmAyupaHlqwiR9dNzHWZbXascoa3txYysurinl9QwkVVXVva3vygx28vamMB66dwIXD+8aoShGRxGHxNhvX5MmTfdmyZbEuo90t2bKX2b99D4AUg1e+NpVROd1jXFXzVVTV8NamMl5eVcxr60soj3BE/JfOH8w9M0bTtZM+R4pI8jGz5e4+ual2EXWPm9l0M9toZgVmdk8Dzz9kZiuCX5vM7EDYczeY2ebg1w3N+zGSxwVn9OGSUdkA1Dr8cP6GGFcUucrqWl5fX8Kdf13B5P95jVseX86clUWnBPbI/t3498tH8vpd0/jprEn07JIeeu7x97Yz/advs2SL5mIXEWlMk2faZpYKbAIuBwqBpcBsd1/XSPuvAme5+z+bWW9gGTAZcGA5cLa772/s/ZL1TBtgXdEhrvr5O5z4X/LMrRdwzpDesS2qEVU1tSwq2MNLq4p5de1uDlU0fG16WHZXrp6Qx9UTchnZv27PQenhCr7z/BoWrKs7jeuNU4bwzemj6JKhs24RSQ6RnmlH8lfxXKDA3bcGv/FTwEygwdAGZgP/GXx8BbDA3fcFX7sAmA48GcH7Jp0xeVl8dtIAnv9oFwDff2UDz956AXZiWbA4sLnkML97dxvz1u7mQHlVg20G9+nC1RNyuXpCHqNzujdaf7/umTzypbP5+4pd/OcLa0PB/4fFH/PmxlJ+eO1Ezh3aNh9aDlVUsXBjGaWHKtrk+zfX4D5duXhEXzLTU9v9vWtqneXb97N8+34uOKMPkwb2bPcaRCQykYT2AGBn2HYhcF5DDc1sMDAUeOM0rx3Q/DKTx79fPpKXVxVTWVPL8u37WbCuhE+PzYl1WQAUlB5h5sOLGrxOnd+rM1dNyOUzE/IYm5cV8QcNM+NzZ+Uz5Yy+fPu51by+oRSA7XvL+cIjS/jKlKF844pRdM5ofZgdqqjitXUlzF1dzNub9lAZZ/O9d8lI5ZOj+nHFuBw+OSqb7pnpTb+ohapravlg2z7mrilm3pqS0C146anG4zedx/nD+rTZe4tIy0US2g399W2sT30W8Ky7n/irHtFrzexm4GaAQYMGRVBSxzWwdxe+eP5gHlsUmB3tgfkbuXR0P9JSY3t3nrvzXy+urRPYeT0yuWpCLldNyGNifo9W9Qj0z8rk0Rsm87cPd/FfL67lcEU17vDYom28ubGUH103gbMHN/+s++Cxk0H9zub4C+pw5ZU1vLy6mJdXF5ORmsLFI/pyxbgcLj+zP726ZrT6+1fV1LJky15eWVPM/LUl7Dt66kQ+VTXOvz2xnL/ffiGD+3Rt9XuKSHRFck37AuB77n5FcPteAHf/fw20/Qi43d0XB7dnA5e4+y3B7d8AC9290e7xZL6mfcK+o5VMfeDN0D3MD3x+AtefMzCmNc1bs5tbn1gOBEa3/+7Gc5g2IpuUlOh33RcfPMY9f1vNW5vKQvvM4F8uGspdnx7VZBdyeFC/vbmMqpqG/42PzcvinCG9SW2Dn6E5KqsD4wO27jna4POpKcYFw/pwxbgcrhjbn37dMyP+3sera1hUsIe5q3ezYF0JB481fEmjb7dO1NTWsj94yWN4v248d9sUstrwbF9ETor0mnYkoZ1GYCDap4BdBAai/aO7r63XbhQwHxjqwW8aHIi2HPhEsNmHBAai7Wvs/RTaAT9/fTM/XrAJgJysTBZ+45KYXO+EwP3Wlz34VmjSly9fMJj7Zo5r0/d0d55ZVsh/v7SOw2ETsAzL7sqPrpvIJwb1qtP+RFC/vLqYd5oI6ivH53LV+FyG9I2fM0l3Z3PpEeat2c0ra3azvvhQg+3M4OxBvZg+LocrxuYwsHeXU9pUVNXw9qYyXlmzm9fWldQ5fuH6Z3VixrhcZozLYfKQ3qwsPMCsR96jsjrQGzF1ZDaP3TA55r08IskgaqEd/GZXAj8BUoHH3P1+M7sPWObuc4Jtvgdkuvs99V77z8C3g5v3u/vvT/deCu2A8spqpj6wMHSt8Z4Zo7l12hlNvKptPLhgEz97fTMAvbtm8MZd0+jZpfXdtZHYdeAY9/xtFe9s3hPal2Lwr1OHcdNFQ3l7055g13fjQT1uQCCorxwXX0F9Otv3HmXemt3MW7ubj3YcaLTd+AE9mD4uh0+d2Y9tZUeZu2Y3b6wv4Wgj98cP6NmZGeNymDE+h7MG9jqlp+SFFbv42lMrQts3ThnC964ZG50fSkQaFdXQbk8K7ZMef287//fvawDIykzjnW9eSo8u7dtduWNvOZc99Fbo7Ov7/zCeWee277gDd+fJD3Zy/8vrGg2j+k4E9VXjcxP+2mzxwWO8uraEV9YU88G2fdQ281d2UO8uzBifw5XjcpkQwdiDB1/dyM/eKAht//dnx/Gl8we3pHQRiZBCuwOoqqnl8gff4uO95QDcMm0Y9844s11r+Jc/LuO19YH7qCfm9+D52y5sk+vYkSjcX843n13F4kYmYBk3IIurxudx5fichA/qxuw9cpwF60qYt3Y3iwr2NNq7MKxvV2aMz2HGuNxmjeYHqK117njyQ+au3g0Erqn/8SvnctEITTUr0lYU2h3Ey6uKuf0vHwLQKS2Fhd+4hNwendvlvd/cUMpX/rA0tP332y+M+T28tbXOnz/YwffnrudoZQ3jB/QIdH134KBuzKGKKt5YX8q8Nbv54ON9ZHfrxPRxOVw5PpeR/bu1ajT/scoarv/NElbvOggEenqev/1CzsjuFq3yRSSMQruDcHdmPryIVYWBP56f/0Q+P76+7RcTOV5dwxUPvR06y//C5IH84NoJbf6+kTpcUcWxqppmjaSW5tl9sIKZD79LyaHAuIqhfbvy/G1T2m08g0gyierc4xI7ZsY900eHtv/2YSF/eX9Hm7/vo+9sCwV2VmYa35w+qolXtK/umekK7DaW0yOTR798DpnpgT8T2/Yc5bY/f0hVHN/rLtLRKbQTwJThfblqQm5o+/++sIZ3w0ZTR1vRgWP8Imwg0r9fPpI+3Tq12ftJ/Bqf34MHr58U2l68ZS/ffWEt8dZDJ5IsFNoJ4ofXTmDcgCwgMFf0v/15OQWlR9rkvf537nqOVQVGaY/O6c4XNXI4qV05Ppe7Lh8Z2n7ygx38YfHHsStIJIkptBNEl4w0Hv3yOfTPCpzxHq6o5qY/Lm1wKsrWWLwlsHLXCf91zVhNriHccelwZk7KC23/90vreHNjaQwrEklO+mucQHJ6ZPK7G86hc3BmtO17y7n18eUcr47s3uWmVNXU8r05Jye6mzkpj/O0cIQQGFvxg89PCN09UOvw1b98xKaSwzGu7FS1tU7JoQp14UuHpNBOMOMG9OAnsyZx4m6eDz7ex7efWxOVP1B/WrKdTSWBLveuGal8+8r2vSdc4ltmeiqPfPls8noEBgAeOR7o7dkbnLUvHny0Yz+XP/QW5/3v61zyo4U8MG8D64oOKcClw1BoJ6ArxubwrXojyn/11pZWfc/SwxX8JDjXOcD/+dQI+mdpdLbU1a97Jo/ecA5dgkul7tx3jFufiF5vT0sdr67hB/M28PlfLWZLWWDhle17y/nlwi1c+bN3+NSDb/HgqxvjsmdApDkU2gnqlqnDuH5yfmj7gXkbmbem+DSvOL0fvLIxtLDEsOyufOXCoa2uUTqmMXlZ/HTWWaHenqUf7+c7z0ent6cl1uw6yDU/X8SvFm785al8AAAP7klEQVRpdIrXrWVH+dkbBXz6obe5/MG3+Olrm9tsIKdIW9LkKgmssrqWL/3ufd7fFlg0LTM9hWdumcL4/B7N+j7Lt+/j879aEtr+0z+fy9SR2VGtVTqeX7+1he+/siG0fe+M0dzSjovaVNXU8vCbBfzijQKqw9L6gmF9+J/PjWNL6RFeXl3Ma+saX0BldE53rp6Qy9UT8hJmMRnpmDQjWpLYf7SSz/1yUWgilH7dO/HCHRdGPNVpTa1zzS/eZW1RYCnI6WNz+PWXzm6zeqXjcHe+8ewqnl1eCASWDX3kS5O5fEz/Nn/vjbsPc9czK1iz6+QSppnpKdw740y+dP7gOvPjV1TVsHBjKS+uKuaN9aWh2xnrOzF3/dUTchtc8lSkLSm0k8iWsiN87uFFHKoIdG+Pyc3imVsvoGuntCZf+8R72/mP4EpindJSeO3fp+kPlkTseHUNX3r0Az74ONDb0yUjladuPp8J+W0zR31NrfPI21t5aMEmKsNmZjt7cC9+dN1EhjZxtlxeWc0bG0p5aWUxb24s5Xh1w7O7TczvwdUT8rhqQi55Pdtnrv+2UHqogtfWl1LrzqWj+yX0zxIvDpRXcvczK7nr06M4Mzcrat9XoZ1kFhfs4cuPfRDqJrx8TH9+88WzT7si1/6jlXzyxws5UF4FwJ2XjeRrl41ol3ql49h75Dif/eUidu47Fto3cWBPrgquMhatD4Fbyo5w9zMr66wvnpGWwt2fHslNFw0jtZmrzx05Xs3r60t4aVUxb20sq/MhINy5Q3pzzaQ8rhyfS++u8T/v+qGKKuat2c0LK3axZMveOtf5zxnSi89MzGPGuFyyu2uWw+baWnaEm/64jG17jjKgZ2eev31K1KZTVmgnoac+2ME9z60Obd8ydRj3nua2re88v5o/B+cxH9i7MwvunEZm8B5wkebYVHKYf/jlYo4EBzOGm5jfg6sm5LY4wGtrnd8v/pgH5m2oc2Y8Mb8HP7puIiP6d29V7RAIutfWBQL8nc1lDS55mpZiXDSiL9dMzOPTY3PoFkFPVns5Xl3DmxvKeGHFLl7fUEplIz0IJ6QYTDmjL5+ZmMsVY3O0CEwEFm/Zw7898SEHj1WF9v34uol8/uz807wqcgrtJHX/y+v47TvbQts/+Px4vnDOoFPardl1kM/84l1O/O//7Zfb51qkdFxrdh3kh/M3sqhgT52BYeGaG+A79pZz97Mr+SA42BIgPdX42qdGcOu0M9pktr6D5VXMX7ebF1cWsahgT4Mj0julpXDZmf35zMQ8LhmVHZMPuzW1zvvb9vLCR0XMXVPM4YpTPzCZwXlDe5OWksLiLQ3/LOmpxtQR2XxmYh6XjekfVx9G4sVfl+7gO8+vCf27zkxP4aHrJzFjfG4Tr4ycQjtJ1dQ6tzy+jNfWB6aYTEsxHr/pPC444+TMZrW1zrW/XsyHwW7GS0Zl8/sbz2nV+ssiJxwor+TVdSXMXV3Mu5tPH+CBtdBPDXB358/v7+B/566nPGzk95m5Wfz4uomMyYvetcTTKTt8nLmri5mzsojl2/c32KZ7pzSuGJfDzEl5XDCsT5tO++vurC06xAsrdvHiymJ2H6posN2Y3Cw+e1Yen5mYFxqUuufIcV5ZXcyLK4tDYxDq65SWwqfO7MfVE/K4dHS/pO95q6l1Hpi3gd+8vTW0r1/3Tjx6w+Soj9tQaCexo8erufbXS1hfHBhZ26NzOs/fNoVh2d0AeHZ5IXc/sxKAjNQU5t85tckBPCItcbC8ilfX7eblZgR4aorxrb+t4p2wlexSU4zbLjmDr146goy02EwvsXNfOS+uKmLOiiI27G54kpa+3TK4anwu10zK4xODekXtg/D2vUeZs6KIv6/YFZo8pr6BvTszc+IAZk7Ka/KSQfHBY7y8qpgXVxWzcueBBtt0zUjl8jGB3oSLR2TH7LjHytHj1Xz9rytYsK4ktG9Mbha/u3FyxHfnNIdCO8kVHTjGzIcXUXY4MMXk0L5def62KaSkGJf+aCF7jgQWGrntkjP4ZtjsaiJt5USAz11dzLsFexq8bgyBwWXh12SH9+vGj6+byMSBbTMivSU2lRxmzooi5qwsYse+8gbbDOjZmUtH96NzRsvPVmtrneU79tcZfBeuT9cMrp6QyzWTBvCJQT1b9CFhx97Ah5EXVzb+YSQrM42pI7MZndOdkf0DXwN7d2n24L9EUXzwGDf9YRnrik/eUnjZmf356axJEd2V0xIKbWHlzgNc/5slocE75w/rzcj+3fnTku0A5PbI5PW7ptElQ9ewpH1FEuBmcPPFw7jz8pFx203r7qwsPMgLK3bx0qri0IfkttQlI5UrxuZwzaQ8Lhrel/QodsdvLjnMi6uKeWllEVv3NHxGf0JmegrD+3VjZL/ujOjfnVE53RjRrzsDenY+7V0r8W514UH+5U9LKTl08v/lzVOH8a3po9v0Q4pCWwCYu7qY2/78YYPP/eIfz+LqCXkNPifSXg6WV7FgfQkvryoKBfiQPl348fUTOXtw71iXF7GaWuf9rXuZs7KIuauLQ/MmRENaijFtZDYzzxrAZWf2a/MP2ieunb+0qpgXVxax68Cxpl8U1CUjlRH9uzOyX7fAWXlOd0b270ZOVmbcj5uZt6aYr/91BRVVgROdtBTjfz47jlnnnjqYN9oU2hLy8JsF/HD+xjr7LhjWh7/863lx/0skyeVgeRUFZYcZN6AHndLi8+w6Esera3h3856ozG/eu2sGnzqzf8zuEXd3Vu86yJpdh9hUcpjNpYfZuPsIe5q5ulv3zDR6d83ACCz1akbocYqBEdxnFtwPKfXapaYYI/sHpp49b2jvqA36c3d+9dYWHph38u9kVmYav/7i2UwZ3jcq79EUhbaEuDt3Pb2S5z7aBQQG9bzytYsZGYX7W0UkOe0/WsmmksPBryOhx/vLq5p+cRT07ZbB9HE5XD0hj3OG9G5x13VldS3ffn51aDpegCF9uvDYjeeEBu+2B4W21HG8uoavP7WC1zeU8q3po7npIq3iJSLR5e7sOVLJ5mCAbyw5EnoczcsF9fXr3okrx+dy1YRczh7UK+Jr6vuOVnLrE8vrzANw3tDe/PqLZ9OrnXs2FNrSIHdXl7iItCt3p+zwcY5W1uDueHCfOzhQe+KxBx4HXhPcH2xb64G5419fX8rc1cWUNjLoLycrkyvH53L1xFzOGtj4iPotZUf45z8sZfvek6P/rzs7n/s/Nz4mt7cptEVEpEOqqXWWfbyPl1YV88qa4tAtrPUN6NmZqybkctX4XCbk9wgF+KKCPfzbE8tDZ/9m8K3po7ll6rCYndQotEVEpMM7MWr/xVXFzFtT3Og19UG9u3DVhFx6dk7nh/M3hib66ZyeykNfmMT0cTntWfYpFNoiIpJUqmpqWbJlLy+tKmL+2pI6i3s0pH9WJ353wzmMG9CjnSpsXKShHVHHvZlNN7ONZlZgZvc00uZ6M1tnZmvN7C9h+x8I7ltvZj8zXVAVEZE2kJ6awtSR2Txw7USWfucyfn/jOXz+E/l0b2AWs3EDsnjh9oviIrCbo8k79M0sFXgYuBwoBJaa2Rx3XxfWZgRwL3Chu+83s37B/VOAC4EJwabvAtOAhdH8IURERMJlpKXwydH9+OTofhyvHsc7m/bw0qoi3t+2jwuH9+W+mWMTcjbISCo+Fyhw960AZvYUMBNYF9bmX4GH3X0/gLuXBvc7kAlkELg/Ph0oQUREpJ10SkvlsjH9uawDLD8cSff4AGBn2HZhcF+4kcBIM1tkZu+Z2XQAd18CvAkUB7/mu/v6+m9gZjeb2TIzW1ZWVtaSn0NERKTDiyS0G7oGXX/0WhowArgEmA08amY9zWw4cCaQTyDoLzWzqad8M/dH3H2yu0/Ozs5uTv0iIiJJI5LQLgQGhm3nA0UNtHnB3avcfRuwkUCIfw54z92PuPsR4BXg/NaXLSIiknwiCe2lwAgzG2pmGcAsYE69Nn8HPglgZn0JdJdvBXYA08wszczSCQxCO6V7XERERJrWZGi7ezVwBzCfQOA+7e5rzew+M7sm2Gw+sNfM1hG4hv0Nd98LPAtsAVYDK4GV7v5iG/wcIiIiHZ4mVxEREYmxqE6uIiIiIrGn0BYREUkQCm0REZEEodAWERFJEHE3EM3MyoDtzXhJX2BPG5WTrHRMo0vHM/p0TKNLxzP6mntMB7t7k7OLxV1oN5eZLYtkxJ1ETsc0unQ8o0/HNLp0PKOvrY6pusdFREQShEJbREQkQXSE0H4k1gV0QDqm0aXjGX06ptGl4xl9bXJME/6atoiISLLoCGfaIiIiSUGhLSIikiASOrTNbLqZbTSzAjO7J9b1JCIze8zMSs1sTdi+3ma2wMw2B//bK5Y1JhIzG2hmb5rZejNba2ZfC+7XMW0BM8s0sw/MbGXweP5XcP9QM3s/eDz/Glw2WJrBzFLN7CMzeym4rWPaCmb2sZmtNrMVZrYsuC/qv/cJG9pmlgo8DMwAxgCzzWxMbKtKSH8Aptfbdw/wuruPAF4PbktkqoG73P1M4Hzg9uC/Sx3TljkOXOruE4FJwHQzOx/4AfBQ8HjuB26KYY2J6msElls+Qce09T7p7pPC7s+O+u99woY2cC5Q4O5b3b0SeAqYGeOaEo67vw3sq7d7JvDH4OM/Ap9t16ISmLsXu/uHwceHCfxRHICOaYt4wJHgZnrwy4FLgWeD+3U8m8nM8oGrgEeD24aOaVuI+u99Iof2AGBn2HZhcJ+0Xn93L4ZACAH9YlxPQjKzIcBZwPvomLZYsBt3BVAKLAC2AAfcvTrYRL/7zfcT4JtAbXC7DzqmreXAq2a23MxuDu6L+u99Wmu/QQxZA/t0/5rEBTPrBvwN+Lq7HwqcyEhLuHsNMMnMegLPA2c21Kx9q0pcZnY1UOruy83skhO7G2iqY9o8F7p7kZn1AxaY2Ya2eJNEPtMuBAaGbecDRTGqpaMpMbNcgOB/S2NcT0Ixs3QCgf1nd38uuFvHtJXc/QCwkMBYgZ5mduKkQ7/7zXMhcI2ZfUzgsuKlBM68dUxbwd2Lgv8tJfDh8lza4Pc+kUN7KTAiOOIxA5gFzIlxTR3FHOCG4OMbgBdiWEtCCV4b/B2w3t0fDHtKx7QFzCw7eIaNmXUGLiMwTuBN4NpgMx3PZnD3e909392HEPi7+Ya7/xM6pi1mZl3NrPuJx8CngTW0we99Qs+IZmZXEviEmAo85u73x7ikhGNmTwKXEFhGrgT4T+DvwNPAIGAHcJ271x+sJg0ws4uAd4DVnLxe+G0C17V1TJvJzCYQGMCTSuAk42l3v8/MhhE4S+wNfAR80d2Px67SxBTsHr/b3a/WMW254LF7PriZBvzF3e83sz5E+fc+oUNbREQkmSRy97iIiEhSUWiLiIgkCIW2iIhIglBoi4iIJAiFtoiISIJQaIuIiCQIhbaIiEiC+P/lOUyePN+6FAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_values = list(range(1,50,2))\n",
    "accs = []\n",
    "for k in k_values:\n",
    "    knn = KNN(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10)\n",
    "    accs.append(np.mean(scores))\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(k_values, accs, lw=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the scores 0.6891098484848485\n"
     ]
    }
   ],
   "source": [
    "print('mean of the scores',np.mean(scores))\n",
    "#So, probabaly 0.7 with k=9 can be a beeter value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to compare the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "\n",
    "#Instantiate a Logistic Regression classifier and assign it to lr.\n",
    "lr =LogisticRegression(C=0.10974987654930568, class_weight=None, dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', solver='liblinear', tol=0.0001, verbose=0, warm_start=False,random_state=SEED)\n",
    "#Instantiate a KNN classifier that considers 27 nearest neighbors and assign it to knn.\n",
    "knn = KNN(algorithm='auto', leaf_size=30, metric='minkowski',metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
    "           weights='uniform')\n",
    "#Instantiate a Decision Tree Classifier with the parameter min_samples_leaf set to 0.13(so each leaf includes 13% of data used in traing) and assign it to dt.\n",
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=0.4, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=0.04, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, \n",
    "            splitter='best', random_state=SEED)\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.698\n",
      "K Nearest Neighbours : 0.635\n",
      "Classification Tree : 0.670\n"
     ]
    }
   ],
   "source": [
    "#*we will use ROC to check the accuracy, since the datset was imbalance we cant use accuracy as a measurement\n",
    "#Iterate over the tuples in classifiers. Use clf_name and clf as the for loop variables:\n",
    "for clf_name, clf in classifiers:\n",
    "# Fit clf to the training set\n",
    "    clf.fit(X_train,y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Calculate accuracy\n",
    "    fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred,pos_label=2)#pos_label when the patient is not sick\n",
    "    accuracy_ROC= auc(fp_rate, tp_rate,'\\n')\n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy_ROC))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for logistics and Classification are better than KNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#Finally, you'll evaluate the performance of a voting classifier that takes the outputs of the models defined in the list classifiers and assigns labels by majority voting.\n",
    "# Import VotingCLassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate roc_curve\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred,pos_label=2)\n",
    "accuracy_ROC= auc(fp_rate, tp_rate,'\\n')\n",
    "# Evaluate Voting Classifier's accuracy on the test set\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy_ROC))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! The voting classifier achieves an roc of almost 70% whcih is close to the percentage we achieved for logistics and decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging classifier: \n",
    "#### Now our task is to predict whether a patient suffers from a liver disease using 10 features including Albumin, age and gender. we'll do so using a Bagging Classifier. We both logistic and decision tree classifier for bagging ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a BaggingClassifier 'bc',number of estimators: number of trees, base_estimator: use decision tree classifier and logistic regression(had the best accuracy),number of samples=50\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50,n_jobs=-1) #when n_jobs=-1, all cpu cores will be used in computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit 'bc' to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_Bag_DT 0.716\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred,pos_label=2)#pos_label when the patient is not sick\n",
    "accuracy_ROC_bc= auc(fp_rate, tp_rate,'\\n')\n",
    "# Evaluate lr's accuracy on the test set\n",
    "print('accuracy_Bag_DT {:.3f}'.format(accuracy_ROC_bc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems, we received a better result.Now let's try it with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc1=BaggingClassifier(base_estimator=lr, n_estimators=50,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=0.10974987654930568, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=1,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=50, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_lr 0.704\n"
     ]
    }
   ],
   "source": [
    "# Predict test set labels\n",
    "y_pred1 = bc1.predict(X_test)\n",
    "# Calculate accuracy\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred1,pos_label=2)#pos_label when the patient is not sick\n",
    "accuracy_ROC_bc1= auc(fp_rate, tp_rate,'\\n')\n",
    "# Evaluate lr's accuracy on the test set\n",
    "print('accuracy_lr {:.3f}'.format(accuracy_ROC_bc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems bagging using logistic regression gives a little bit better prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we want to use ,OUT OF BAG(OOB) instances to imporve the accuracy without using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we repeat the process\n",
    "# Instantiate a BaggingClassifier 'bc'; set oob_score= True \n",
    "\n",
    "bc3 = BaggingClassifier(base_estimator=dt, n_estimators=300,\n",
    "                               oob_score=True, n_jobs=-1,random_state=SEED)\n",
    "bc4= BaggingClassifier(base_estimator=lr, n_estimators=300,\n",
    "                               oob_score=True, n_jobs=-1,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit 'bc' to the traing set\n",
    "bc3.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred3 = bc3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_ROC_oob_DT 0.692\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred3,pos_label=2)#pos_label when the patient is not sick\n",
    "accuracy_ROC_oob_DT= auc(fp_rate, tp_rate,'\\n')\n",
    "# Evaluate lr's accuracy on the test set\n",
    "print('accuracy_ROC_oob_DT {:.3f}'.format(accuracy_ROC_oob_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with logistics\n",
    "# Fit 'bc' to the traing set\n",
    "bc4.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred4 = bc4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_ROC_oob_Lr 0.704\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred4,pos_label=2)#pos_label when the patient is not sick\n",
    "accuracy_ROC_oob_Lr= auc(fp_rate, tp_rate,'\\n')\n",
    "# Evaluate lr's accuracy on the test set\n",
    "print('accuracy_ROC_oob_Lr {:.3f}'.format(accuracy_ROC_oob_Lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_ROC_oob_DT: 0.692\n",
      "accuracy_ROC_oob_Lr: 0.704\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_ROC_oob_DT: {:.3f}'.format(accuracy_ROC_oob_DT))\n",
    "# Print OOB accuracy\n",
    "print('accuracy_ROC_oob_Lr: {:.3f}'.format(accuracy_ROC_oob_Lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Roc sore was not improved .So, let's try other decision tree models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=0.12, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=-1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [9, 18, 27, 36, 45, 54, 63], 'max_depth': [1, 5, 10, 15, 20, 25, 30], 'min_samples_leaf': [1, 2, 4, 6, 8, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    " \n",
    "# Instantiate a random forests classifier 'rf' 400 estimators\n",
    "rfc = RandomForestClassifier(n_estimators=400,min_samples_leaf=0.12,bootstrap=True,n_jobs=-1,max_features='sqrt', random_state=SEED) \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : [9, 18, 27, 36, 45, 54, 63],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25, 30],\n",
    "           \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]\n",
    "           }\n",
    "    \n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10)\n",
    "CV_rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=27, n_jobs=-1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=36, n_jobs=-1,\n",
    "            oob_score=False, verbose=0, warm_start=False,random_state=SEED)\n",
    "rf.fit(X_train,y_train)\n",
    "# Predict the test set labels 'y_pred'\n",
    "y_pred5 = rf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_ROC_rf 0.663\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred5,pos_label=2)#pos_label when the patient is not sick\n",
    "accuracy_ROC_rf= auc(fp_rate, tp_rate,'\\n')\n",
    "# Evaluate lr's accuracy on the test set\n",
    "print('accuracy_ROC_rf {:.3f}'.format(accuracy_ROC_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAD8CAYAAAASViG0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHQNJREFUeJzt3XuUXFWd9vHvQ0dJoIE0hPjikNiCCIJAYhokCJjBOCqggMCKAkrA1yxkeMO4RMTxFmWp3JRpB29xlhNuAoJcVDDcQUAjdIdc8Q0oicOIM21IuCThjaT5vX+cnaGoVN+qu6p6p5/PWr3q1K599vlVre482eecOkcRgZmZWa62aXQBZmZmg+EgMzOzrDnIzMwsaw4yMzPLmoPMzMyy5iAzM7OsOcjMzCxrDjIzM8uag8zMzLI2qtEFjATjxo2L1tbWRpdhZpaVzs7O1RGxa1/9HGR10NraSkdHR6PLMDPLiqQ/9aefdy2amVnWHGRmZpY1B5mZmWXNQWZmZlnzyR510NXdRfva9kaXYWZWV+e0nFOX7XhGZmZmWatpkEkaK+msPvq0Sjq5lnWk7fxzP/vdLmlsresxM7OhUesZ2Vig1yADWoFBB5kKvb2ffgVZRBwVEc8Nth4zM6uPWgfZhcCekhZJuiT9LJO0VNKMkj6Hpz6frjSIpJmSbpU0X9IKSV9J7a2Sfi/pe8BCYIKkj6bxl0m6KPW7EBiTtnFNajtV0iOp7YeSmlL7KknjSsb+kaTlku6UNCb1mS3pcUlLJF1Xyw/QzMx6V+sgOx/4Y0RMAhYAk4ADgenAJZJ2S30ejIhJEXFZL2MdDJySxjhJUltq3xu4MiImAy8DFwFHpn4HSTouIs4HXkrbOEXS24AZwLtSbd1p7HJ7Ad+NiP2A54ATSt7X5Ig4ADizUrGSZknqkNSxbvW6Pj8oMzOrTj1P9jgMuDYiuiPiv4EHgIMGsP5dEfFsRLwE3JTGA/hTRCxIywcB90fEXyNiE3ANcESFsd4DTAEelbQoPd+jQr+VEbEoLXdS7AYFWAJcI+lUYFOlYiNibkS0RURb87jmAbxNMzMbiHqefq9Brh89PF9fxTYEXBERn++j38aS5W5gTFo+miIgPwR8SdJ+KTjNzKzOaj0jexHYIS3/GpghqUnSrhRB8EhZn968V9LO6TjVccDDFfr8Dnh3OsbVBHyUYuYH8LKk16Xle4ATJY0HSOO+qT9vKJ1QMiEi7gPOozihxVMuM7MGqemMLCKelfSwpGXAryh2yS2mmE2dFxH/JelZYJOkxcC8Xo6TPQRcBbwF+ElEdEhqLdveXyR9HriPYtZ1e0Tcml6eCyyRtDAdJ/sicGcKppeBfwT6c6XlJuBqSTulbVzmsxzNzBpHEeV77IYfSTOBtog4u9G1VGPi5InxmXs/0+gyzMzqarBX9pDUGRFtffXzJarqYHzT+LpdqsXMbKQZVkEm6X0Up8+XWhkRxwPz6l+RmZkNd8MqyCLiDuCORtdhZmb58EWDzcwsaw4yMzPLmoPMzMyy5iAzM7OsOcjMzCxrDjIzM8uag8zMzLLmIDMzs6wNqy9Eb626urtoX9ve6DLMzIbUcLn0nmdkZmaWtZoGmaSxks7qo0+rpJP76DNT0uU9vPabknGWpeU2Sd+pot51PbR/TdL0gY5nZma1V+sZ2Vig1yADWoFeg6w3EXFohbaOiJhd3i6pql2pEfHliLi7mnXNzKy2ah1kFwJ7Slok6ZL0s0zSUkkzSvocnvp8upexJkiaL2mFpK9sbqw0i5I0TdIv0/IcSXMl3QlcWT67k/RLSdNKnn9L0kJJ96Q7WSNpnqQT0/IqSV9NfZZK2qf6j8fMzAar1kF2PvDHiJgELAAmAQcC04FLJO2W+jwYEZN6uTs0wMHAKWmMkyT1ebO1ElOAYyOir5nf9sDCiHgH8ADwlR76rU59vg+cW6mDpFmSOiR1rFtdcY+lmZkNgXqe7HEYcG1EdEfEf1MExUEDWP+uiHg2Il4Cbkrj9dfP03p9eQW4Pi1f3cs2bkqPnRS7RrcQEXMjoi0i2prHNQ+gVDMzG4h6BpkGuX708bw360uWN/Ha9z16ANvcbGN67MZfYTAza6haB9mLwA5p+dfADElN6djTEcAjZX16815JO0saAxwHPFxlTauASZK2kTSBYpflZtsAJ6blk4GHqtyGmZnVSU1nExHxrKSH02nxvwKWAIspZjrnRcR/SXoW2CRpMTCvl+NkDwFXAW8BfhIRHVWW9TCwElgKLAMWlry2HthPUifwPDBjy9XNzGw4UcRA9tBZNdra2qKjo9rcNTMbmSR1RkSfJ/b5yh5mZpa1YXWigqT3AReVNa+MiOMbUY+ZmQ1/wyrIIuIO4I5G12FmZvnwrkUzM8uag8zMzLLmIDMzs6w5yMzMLGsOMjMzy5qDzMzMsuYgMzOzrA2r75Ftrbq6u2hf297oMsxsK3NOyzmNLmFY8IzMzMyy5iAzM7OsDTjIJM2RdK6kr0maPtgCJI2VdFYffaZJ+mUPr90uaWxaXpce3yjpxipqWSVpXIX2MyV9fKDjmZlZ7VV9jCwivlypXVJTRHQPYKixwFnA96qs46gKbc/w6g0yS2sbFRGbqtjGD6qpzczMaq9fMzJJX5C0QtLdwN6pbZ6kE9PyKklflvQQcJKkPSXNl9Qp6UFJ+6R+b5B0s6TF6edQ4EJgT0mLJF3SSxk7pnUfl/QDSduUbPs1syhJrelmnkiaKekGSb8A7iyf3Um6XNLMktU/K+mR9POW1GeOpHPT8v2SLkqvPyHp8P58hmZmVht9zsgkTQE+AkxO/RcCnRW6/r+IOCytcw9wZkQ8KemdFLOtI4HvAA9ExPGSmoBm4Hzg7RExqY9SDgb2Bf4EzAc+DPR39+FU4ICIWCNpWh99X4iIg9OuxH8BjqnQZ1TqcxTwFWCLXaySZgGzAFp2b+lnmWZmNlD9mZEdDtwcERsi4gXg5z30ux5AUjNwKHCDpEXAD4HdUp8jge8DRER3RDw/gFofiYin0m7La4HDBrDuXRGxpp99ry15nNpDn5vSYyfQWqlDRMyNiLaIaGse19zvQs3MbGD6e4ws+tFnfXrcBniuHzOsgSqvoT81bba+ZHkTrw3w0b2M29M2NqbHbvxdPDOzhurPjOzXwPGSxkjaAfhgb53TrG2lpJMAVDgwvXwP8KnU3iRpR+BFYId+1HGwpDenY2MzgIf6sU4lfwL2lbStpJ2A95S9PqPk8bdVbsPMzOqkzyCLiIUUuw0XAT8DHuzHuKcAn5C0GFgOHJvazwH+XtJSit1y+0XEs8DDkpb1cbLHbylODFkGrARu7kcdld7P08BPgSXANcBjZV22lfS7VOunq9mGmZnVjyIGsofOqtHW1hYdHR2NLsPMLCuSOiOira9+vrKHmZllbVidqCBpf+CqsuaNEfHORtRjZmbD37AKsohYCgz12Y5mZrYV865FMzPLmoPMzMyy5iAzM7OsOcjMzCxrDjIzM8uag8zMzLLmIDMzs6wNq++Rba26urtoX9ve6DLMLHPntJzT6BKGJc/IzMwsa9kHmaRVksZJapW0rEbb+DdJ+9ZibDMzGxzvWuyHiPjfja7BzMwqy2pGJukWSZ2SlkuaVaHLKElXSFoi6UZJ26X1Vkkal5bbJN2fluek/nemPh+WdLGkpZLmS3pd6ne/pLa0vE7S1yUtlrRA0hvq8+7NzKySrIIMOCMipgBtwGxJu5S9vjcwNyIOAF4AzurHmHsCR1Pc/PNq4L6I2B94KbWX2x5YEBEHUtw9+5OVBpU0S1KHpI51q9f1owwzM6tGbkE2O911egEwAdir7PWnI+LhtHw1cFg/xvxVRLwMLAWagPmpfSnQWqH/34BfpuXOHvoQEXMjoi0i2prHNfejDDMzq0Y2x8gkTQOmA1MjYkPaPTi6rFv57a43P9/Eq6Fdvs5GgIh4RdLL8eots1+h8udT2qe7hz5mZlYnOc3IdgLWphDbBzikQp+Jkqam5Y8CD6XlVcCUtHxCTas0M7O6yinI5lOczLEEuIBi92K53wOnpT47A99P7V8F2iU9SDGLMjOzrYRe3UtmtTJx8sT4zL2faXQZZpa5kXZlD0mdEdHWVz8f36mD8U3jR9wvoJlZveS0a9HMzGwLDjIzM8uag8zMzLLmIDMzs6w5yMzMLGsOMjMzy5qDzMzMsuYgMzOzrDnIzMwsaw4yMzPLmi9RVQdd3V20r21vdBlmljFf5q5nnpGZmVnWHGQVSJok6aiS5x+SdH4jazIzs8pGbJBJ6m236iTgf4IsIn4eERfWviozMxuorI6RSboFmACMBtojYq6kTwCfA54BngQ2RsTZPaw/D1gDTAYWSroe+BdgDPAScDqwEvgaMEbSYcA30+ttEXG2pDcBPwZ2Bf4KnB4R/1Gjt2xmZn3IKsiAMyJijaQxwKOSbgO+BLwDeBG4F1jcxxhvBaZHRLekHYEjImKTpOnANyLiBElfJgUXgKSZJetfDlwZEVdIOgP4DnBc+UYkzQJmAbTs3jKIt2xmZr3JLchmSzo+LU8APgY8EBFrACTdQBFUvbkhIrrT8k7AFZL2AgJ4XT9qmAp8OC1fBVxcqVNEzAXmQnGH6H6Ma2ZmVcjmGJmkacB0YGpEHAg8BqyoYqj1JcsXAPdFxNuBD1Lsshwoh5SZWQNlE2QUs6e1EbFB0j7AIcB2wLsltaSTN06oYsw/p+WZJe0vAjv0sM5vgI+k5VOAhwa4TTMzG0I5Bdl8YJSkJRQzqQUUIfQN4HfA3cDjwPMDGPNi4JuSHgaaStrvA/aVtEjSjLJ1ZgOnpzo+BvhbimZmDZTNMbKI2Ah8oLxdUkc6e3EUcDNwZy9jzCx7/ltee0ztS6l9DXBQ2erz0murgCMH/AbMzKwmsgmyXsxJZxyOpgixWxpczxbGN4335WXMzGok+yCLiHPL2yR9ATiprPmGiPh6faoyM7N6yT7IKkmB5dAyMxsBcjrZw8zMbAsOMjMzy5qDzMzMsuYgMzOzrDnIzMwsaw4yMzPLmoPMzMyy5iAzM7OsbZVfiB5uurq7aF/b3ugyzKwPvpRcnjwjMzOzrDnIzMwsaw4yQNItkjolLZc0K7V9QtITku6X9CNJl6f2XSX9TNKj6eddja3ezGxk8zGywhkRsUbSGOBRSbdR3JvsHRR3i74XWJz6tgOXRcRDkiYCdwBva0TRZmbmINtstqTj0/IEijs/P5BusImkG3j1BpzTKe4evXndHSXtEBEvlg6YZnazAFp2b6lx+WZmI9eIDzJJ0yjCaWpEbJB0P7CCnmdZ26S+L/U2bkTMBeYCTJw8MYasYDMzew0fI4OdgLUpxPYBDgG2A94tqUXSKOCEkv53AmdvfiJpUl2rNTOz13CQwXxglKQlwAXAAuDPwDeA3wF3A48Dz6f+s4E2SUskPQ6cWf+SzcxssxG/azEiNgIfKG+X1BERc9OM7GaKmRgRsRqYUd8qzcysJyM+yHoxR9J0YDRFiN1S7UDjm8b7igFmZjXiIOtBRJzb6BrMzKxvPkZmZmZZc5CZmVnWHGRmZpY1B5mZmWXNQWZmZllzkJmZWdYcZGZmljUHmZmZZc1BZmZmWfOVPeqgq7uL9rXtjS7DbNjzpdysGp6RmZlZ1hxkVZLUKunkRtdhZjbSOciq1wo4yMzMGmxEHiOTtD3wU2B3oInihpovAt8GVgMLgT0i4hhJc4A9gb8DJgAXR8SPgAuBt0laBFwREZfV/Y2YmdnIDDLg/cAzEXE0gKSdgGXAERGxUtK1Zf0PAA4Btgcek3QbcD5wbkQcU8e6zcyszEjdtbgUmC7pIkmHA28GnoqIlen18iC7NSJeSneHvg84uK8NSJolqUNSx7rV64a0eDMze9WIDLKIeAKYQhFo3wSO7WuVPp5X2sbciGiLiLbmcc3VFWpmZn0akUEm6Y3Ahoi4GrgUOBTYQ1Jr6jKjbJVjJY2WtAswDXiU4pjaDnUp2MzMejRSj5HtD1wi6RXgZeBTwG7AfEmrgUfK+j8C3AZMBC6IiGck/RXYJGkxMM8ne5iZNcaIDLKIuAO4o7RNUnNE7CNJwHeBjpKXn4iIWWVjvAy8p+bFmplZr0ZkkPXgk5JOA14PPAb8cKgGHt803pfeMTOrEQdZknYNbrF7MCLm1L8aMzPrrxF5soeZmW09HGRmZpY1B5mZmWXNQWZmZllzkJmZWdYcZGZmljUHmZmZZc1BZmZmWXOQmZlZ1nxljzro6u6ifW17o8swG1Z82TYbKp6RmZlZ1hxkVZI0TdKhja7DzGykc5BVbxrFDTnNzKyBRuQxMknbAz8FdgeagAso7vj8bWA1sBDYIyKOkbQz8GNgD2ADMAt4ATgT6JZ0KvB/IuLBur8RMzMbmUEGvB94JiKOBpC0E7AMOCIiVkq6tqTvV4HHIuI4SUcCV0bEJEk/ANZFxKWVNiBpFkXo0bJ7Sy3fi5nZiDZSdy0uBaZLukjS4cCbgaciYmV6vTTIDgOuAoiIe4FdUvD1KiLmRkRbRLQ1j2se4vLNzGyzERlkEfEEMIUi0L4JHNtLd1UaohZ1mZnZwI3IIJP0RmBDRFwNXEpx0sYeklpTlxkl3X8NnJLWmwasjogXKI6p7VCnks3MrAcj9RjZ/sAlkl4BXgY+BewGzJe0GnikpO8c4N8lLaE42eO01P4L4EZJx+KTPczMGmZEBllE3AHcUdomqTki9pEk4LtAR+q7hgq7HtPuyQPqUK6ZmfViRAZZDz4p6TTg9cBjwA+HauDxTeN9OR4zsxpxkCURcRlwWaPrMDOzgRmRJ3uYmdnWw0FmZmZZc5CZmVnWHGRmZpY1B5mZmWXNQWZmZllzkJmZWdYcZGZmljUHmZmZZc1X9qiDru4u2te2N7oMs5ryZdisUTwjMzOzrG01QSZplaRxklolLRvAegPqb2Zmw8tWE2RmZjYyZRlkkm6R1ClpuaRZvfTbQ9Jjkg6SNFPSrZLmS1oh6SslXZsk/SiNd6ekMWn9SZIWSFoi6WZJLal9tqTHU/t1NX67ZmbWiyyDDDgjIqYAbcBsSbuUd5C0N/Az4PSIeDQ1HwycAkwCTpLUltr3Ar4bEfsBzwEnpPYrgc9FxAHAUmBz+J0PTE7tZ1YqUNIsSR2SOtatXjfIt2tmZj3JNchmS1oMLAAmUARRqV2BW4FTI2JRSftdEfFsRLwE3AQcltpXlvTrBFol7QSMjYgHUvsVwBFpeQlwjaRTgU2VCoyIuRHRFhFtzeOaq3+nZmbWq+yCTNI0YDowNSIOpLib8+iybs8DTwPvKmuPHp5vLGnrpu+vJRwNfBeYAnRK8tcYzMwaJLsgA3YC1kbEBkn7AIdU6PM34Djg45JOLml/r6Sd0zGw44CHe9pIRDwPrJV0eGr6GPCApG2ACRFxH3AeMBbwlMvMrEFynEnMB86UtARYQbF7cQsRsV7SMcBdktan5oeAq4C3AD+JiA5Jrb1s6zTgB5K2A54CTgeagKvTrkcBl0XEc4N/W2ZmVo3sgiwiNgIfqPBSa3pcDbw99X0OOAhA0kygKyLOLhtv1eb+6fmlJcuLqDzjO6xCm5mZNUB2QZaj8U3jffkeM7MaGTFBFhHzgHkNLsPMzIZYjid7mJmZ/Q8HmZmZZc1BZmZmWXOQmZlZ1hxkZmaWNQeZmZllzUFmZmZZc5CZmVnWRswXohupq7uL9rXtDdu+rypiZlszz8jMzCxrDrIKJM2TdGKj6zAzs745yIaAb6xpZtY42f8DLOlLwCkUd4ReDXQCN1PcwXlXYAPwyYj4v5LmAS8AbcD/As6LiBslCfhX4EhgJcV9xjaPPwX4NsXNM1cDMyPiL5LuB35DcRfqnwPfqvmbNTOzLWQdZJLagBOAyRTvZSFFkM0FzoyIJyW9E/geRUgB7EZxP7F9KALoRuB4YG9gf+ANwOPAjyW9jiLgjo2Iv0qaAXwdOCONNTYi3l3zN2pmZj3KOsgoAunWiHgJQNIvgNHAocANxUQLgG1L1rklIl4BHpf0htR2BHBtRHQDz0i6N7XvTXHTzbvSWE3AX0rGur6nwiTNAmYBtOzeUvUbNDOz3uUeZKrQtg3wXERM6mGdjT2sHz2MvzwipvYw1vqeCouIuRQzQyZOnlhpbDMzGwK5n+zxEPBBSaMlNQNHUxwTWynpJAAVDuxjnF8DH5HUJGk34O9T+wpgV0lT01ivk7RfTd6JmZlVJesgi4hHKY5zLQZuAjqA5ylO/viEpMXAcuDYPoa6GXgSWAp8H3ggjf834ETgojTWIordlmZmNkzkvmsR4NKImCNpO4qZ1bciYiXw/vKOETGz7Hlzegzg7EqDR8QiimNo5e3TBl25mZkN2tYQZHMl7UtxkscVEbGw0QWVG9803peJMjOrkeyDLCJObnQNZmbWOFkfIzMzM3OQmZlZ1hxkZmaWNQeZmZllTcWZ51ZLkl6k+HJ1bsZRXCg5N7nWDfnW7rrrK9e6YWC1vykidu2rU/ZnLWZiRUS0NbqIgZLU4brrK9faXXd95Vo31KZ271o0M7OsOcjMzCxrDrL6mNvoAqrkuusv19pdd33lWjfUoHaf7GFmZlnzjMzMzLLmIBskSe+XtELSHySdX+H1bSVdn17/naTWktc+n9pXSHpfDnVLeq+kTklL0+OROdRd8vpESesknVuvmtN2B/N7coCk30panj730TnUnu7fd0Wq+feSPj/M6j5C0kJJmySdWPbaaZKeTD+n1a/q6uuWNKnk92SJpBk51F3y+o6S/izp8gFvPCL8U+UP0AT8EdgDeD3FfdH2LetzFvCDtPwR4Pq0vG/qvy3w5jROUwZ1TwbemJbfDvw5h8+75PWfATcA5+ZQN8VXZJYAB6bnu9Tr92QIaj8ZuC4tbwesAlqHUd2twAHAlcCJJe07A0+lx5a03JJB3W8F9krLbwT+Aowd7nWXvN4O/AS4fKDb94xscA4G/hART0VxE87r2PImnscCV6TlG4H3SFJqvy4iNkZx/7Q/pPGGdd0R8VhEPJPalwOjJW1bl6oH93kj6TiKf5SW16nezQZT9z8ASyJiMUBEPBsR3XWqGwZXewDbSxoFjAH+BrxQn7L7rjsiVkXEEuCVsnXfB9wVEWsiYi1wFxXub1gjVdcdEU9ExJNp+RmgC+jzy8RDZDCfN5KmAG8A7qxm4w6ywfk74OmS5/+Z2ir2iYhNFHew3qWf69bKYOoudQLwWERsrFGd5aquW9L2wOeAr9ahznKD+bzfCoSkO9JumfPqUG/FupKB1H4jsJ5iZvAfFDfBXVPrgstrSgby9zXc/zb7JOlgipnRH4eorr5UXbekbYBvAZ+tduO+ssfgqEJb+WmgPfXpz7q1Mpi6ixel/YCLKGYM9TKYur8KXBYR69IErZ4GU/co4DDgIGADcI+kzoi4Z2hL7NFgaj8Y6KbYzdUCPCjp7oh4amhLrGgwf1/D/W+z9wGk3YCrgNMiYovZT40Mpu6zgNsj4ulq/zY9Ixuc/wQmlDzfHXimpz5pF8tOwJp+rlsrg6kbSbsDNwMfj4h6/Y/vNTUlA6n7ncDFklYB/wT8s6Sza11weU3JQH9PHoiI1RGxAbgdeEfNK65QVzKQ2k8G5kfEyxHRBTwM1OuySoP5+xruf5s9krQjcBvwxYhYMMS19WYwdU8Fzk5/m5cCH5d04YC2Xo8DgVvrD8X/lp+iOFlj8wHO/cr6/COvPRD+07S8H6892eMp6neyx2DqHpv6n5DT513WZw71PdljMJ93C7CQ4mSJUcDdwNGZ1P454N8p/re+PfA4cMBwqbuk7zy2PNljZfrsW9LyzhnU/XrgHuCf6vX7MRR1l702kypO9qjrm90af4CjgCco9kV/IbV9DfhQWh5NcZbcH4BHgD1K1v1CWm8F8IEc6ga+SHHcY1HJz/jhXnfZGHOoY5ANwe/JqRQnqCwDLs7ldxxoTu3LKULss8Os7oMoZhLrgWeB5SXrnpHezx+A03OoO/2evFz2tzlpuNddNsZMqggyX9nDzMyy5mNkZmaWNQeZmZllzUFmZmZZc5CZmVnWHGRmZpY1B5mZmWXNQWZmZllzkJmZWdb+P0+gUi/VPyKyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a pd.Series of features importances\n",
    "importances_rf = pd.Series(rf.feature_importances_,index = X.columns)\n",
    "\n",
    "# Sort importances_rf                                   \n",
    "sorted_importances_rf = importances_rf.sort_values()       \n",
    "\n",
    "\n",
    "# Make a horizontal bar plot\n",
    "sorted_importances_rf.plot(kind='barh',color='lightgreen') \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Ada Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a classification-tree 'dt'//we have done this before (dt = DecisionTreeClassifier(max_depth=1,random_state=SEED))\n",
    "\n",
    "# Instantiate an AdaBoost classifier 'adab_clf'\n",
    "adb_clf = AdaBoostClassifier(base_estimator=dt,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=0.4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=0.04, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit 'adb_clf' to the training set\n",
    "adb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7754702194357367\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set probabilities of positive class/ The predicted class probability is the fraction of samples of the same class in a leaf. And the prediction for a random forest is the average on all trees : The predicted class probabilities of an input sample is computed as the mean predicted class probabilities of the trees in the forest\n",
    "y_pred_proba = adb_clf.predict_proba(X_test)[:,1]\n",
    "#*we will use ROC to check the accuracy\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred_proba,pos_label=2)\n",
    "auc_ada_prob= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_ada_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662421630094044\n"
     ]
    }
   ],
   "source": [
    "y_pred = adb_clf.predict(X_test)\n",
    "#*we will use ROC to check the accuracy\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred,pos_label=2)\n",
    "auc_ada= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_ada)\n",
    "# the results was closer to Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': [0.1, 0.05, 0.02, 0.01], 'max_depth': [4, 6, 8], 'min_samples_leaf': [20, 50, 100, 150], 'max_features': [1.0, 0.3, 0.1], 'verbose': [1, 3, 5, 7]}\n"
     ]
    }
   ],
   "source": [
    "gb_grid_params = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'min_samples_leaf': [20, 50,100,150],\n",
    "              'max_features': [1.0, 0.3, 0.1],\n",
    "              'verbose' : [1,3,5,7]   \n",
    "              }\n",
    "print(gb_grid_params)\n",
    "\n",
    "gb_gs = GradientBoostingClassifier(n_estimators = 200,random_state=SEED)\n",
    "\n",
    "gb1 = GridSearchCV(gb_gs,gb_grid_params,cv=2,\n",
    "                               \n",
    "                               n_jobs=-1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3150            0.60s\n",
      "         2           1.2540            0.69s\n",
      "         3           1.2047            0.59s\n",
      "         4           1.1577            0.54s\n",
      "         5           1.1116            0.54s\n",
      "         6           1.0695            0.52s\n",
      "         7           1.0295            0.47s\n",
      "         8           0.9950            0.45s\n",
      "         9           0.9669            0.44s\n",
      "        10           0.9430            0.44s\n",
      "        20           0.7388            0.31s\n",
      "        30           0.5989            0.24s\n",
      "        40           0.5028            0.20s\n",
      "        50           0.4295            0.18s\n",
      "        60           0.3719            0.16s\n",
      "        70           0.3238            0.14s\n",
      "        80           0.2793            0.13s\n",
      "        90           0.2412            0.11s\n",
      "       100           0.2129            0.10s\n",
      "       200           0.0588            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "              max_features=0.3, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=20, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              presort='auto', random_state=1, subsample=1.0, verbose=1,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb1.fit(X_train, y_train)\n",
    "# Predict test set labels\n",
    "y_pred = gb1.predict(X_test)\n",
    "#*we will use ROC to check the accuracy\n",
    "gb1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.627742946708464\n"
     ]
    }
   ],
   "source": [
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred,pos_label=2)\n",
    "auc_gb_gs= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_gb_gs)\n",
    "# the results was closer to Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6622257053291536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate gb\n",
    "gb = GradientBoostingClassifier(max_depth=4,n_estimators=200, random_state=SEED)\n",
    "# Fit gb to the training set\n",
    "gb.fit(X_train,y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred_gb ,pos_label=2)\n",
    "auc_gb= auc(fp_rate, tp_rate,'\\n')\n",
    "print(auc_gb)\n",
    "# the results was closer to Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 4,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 200,\n",
       " 'presort': 'auto',\n",
       " 'random_state': 1,\n",
       " 'subsample': 1.0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
